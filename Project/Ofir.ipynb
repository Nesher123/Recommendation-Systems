{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations Systems\n",
    "## Course Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to let you practice in a data scientist daily work by leveraging recommender\n",
    "systems algorithms you learnt in the course and customize them in order to solve real business\n",
    "problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a dataset based on the <a href='https://grouplens.org/datasets/movielens/1m/'>MovieLens 1M rating dataset</a> after some pre-processing to adapt it to an implicit feedback use case scenario.  \n",
    "You can download the dataset used by <a href='https://github.com/hexiangnan/neural_collaborative_filtering'>this implementation</a> of the paper Neural Collaborative Filtering or from the NeuralCollaborativeFiltering_implicit notebook in Moodle.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d314f57b62da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense, Reshape,  Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from keras.layers import Multiply, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 8 # size of embedding size. Can be split to 4 different params potentially.\n",
    "num_negatives = 4 # how many negative samples per positive sample?\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "verbose = 1\n",
    "epochs = 10\n",
    "TOP_K = 10\n",
    "topK = 10 #used to evaluate the model. Top K recommendations are used. \n",
    "num_users = len(training_data_df.user_input.unique())\n",
    "num_items = len(training_data_df.item_input.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "# Read the training file\n",
    "training = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.train.rating', sep='\\t', names=column_names)\n",
    "\n",
    "# Read the test file\n",
    "test_rating = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.rating', sep='\\t', names=column_names)\n",
    "\n",
    "\n",
    "negative_ids = ['(user_id, item_id)']\n",
    "\n",
    "for i in range(1,100):\n",
    "    negative_ids.append(f'id-{i}')\n",
    "\n",
    "test_negative = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.negative', sep='\\t', names=negative_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ../../online-algo/hw3/ml-1m/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qySSli3hjmaU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ru7vvSljjmaU",
    "outputId": "b3ede376-447e-4f78-8566-ae163c85f34d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "folder = './ml-1m/'\n",
    "df = pd.read_csv(folder+'ratings.dat', sep='::', names=names, engine='python')\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ratings(df):\n",
    "    mapping_user, mapping_item = defaultdict(int), defaultdict(int)\n",
    "    counter_user, counter_item = 0, 0\n",
    "    user_index, item_index = 0, 0\n",
    "    \n",
    "    n_users = df.user_id.unique().shape[0]\n",
    "    n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "    ratings = np.zeros((n_users, n_items))\n",
    "\n",
    "    for idx, row in enumerate(df.itertuples()):\n",
    "        row_user_idx, row_item_idx, row_rating = row[1]-1, row[2]-1, row[3]\n",
    "        \n",
    "        if row_user_idx not in mapping_user:\n",
    "            user_index = counter_user\n",
    "            mapping_user[row_user_idx] = user_index\n",
    "            counter_user += 1\n",
    "        else:     \n",
    "            user_index = mapping_user[row_user_idx]\n",
    "\n",
    "        if row_item_idx not in mapping_item:\n",
    "            item_index = counter_item\n",
    "            mapping_item[row_item_idx] = item_index        \n",
    "            counter_item += 1\n",
    "        else:\n",
    "            item_index = mapping_item[row_item_idx]            \n",
    "\n",
    "        ratings[user_index, item_index] = row_rating\n",
    "\n",
    "    ic(ratings.shape)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pYBPe8vyjmaV",
    "outputId": "4090675d-b314-46b6-8faa-d8aa233aa860"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| ratings.shape: (6040, 3706)\n"
     ]
    }
   ],
   "source": [
    "rating_train = build_ratings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "znCqCTMtjmaW",
    "outputId": "478c6850-880c-4a9b-b2dd-6638ef7962b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 users\n",
      "3704 items\n",
      "Sparsity: 4.44%\n"
     ]
    }
   ],
   "source": [
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%'.format(sparsity))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Matrix Factorization with custom loss (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Answer:\n",
    "\n",
    "Given\n",
    "$$\n",
    "L=-\\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left(y_{i, j} \\log \\left(\\sigma\\left(\\mu+p_{i}+o_{j}+\\boldsymbol{u}_{i}^{T} v_{j}\\right)\\right)+\\left(1-y_{i, j}\\right) \\log \\left(1-\\sigma\\left(\\mu+p_{i}+o_{j}+\\boldsymbol{u}_{i}^{T} v_{j}\\right)\\right)\\right)\n",
    "$$\n",
    "\n",
    "Note that:\n",
    "$$\n",
    "\\log (\\sigma (z)) \\newline\n",
    "= \\log (\\frac{1}{1+e^{-z}}) \\newline\n",
    "= \\log(1) - \\log(1+e^{-z}) \\newline\n",
    "= -\\log(1+e^{-z})\n",
    "$$\n",
    "* (Here, we used the fact that $\\log(\\frac{x}{y}) = \\log(x) - \\log(y)$)\n",
    "\n",
    "Similarly:\n",
    "$$\n",
    "\\log (1 - \\sigma (z)) \\newline \\newline\n",
    "= \\log (1 - \\frac{1}{1+e^{-z}}) \\newline\n",
    "= \\log (\\frac{1+e^{-z} - 1}{1+e^{-z}}) \\newline\n",
    "= \\log (\\frac{e^{-z}}{1+e^{-z}}) \\newline\n",
    "= \\log(e^{-z}) - \\log(1+e^{-z}) \\newline\n",
    "= -z - \\log(1+e^{-z}) \\newline\n",
    "= -\\big( z + \\log(1+e^{-z}) \\big)\n",
    "$$\n",
    "\n",
    "\n",
    "**Denote** $\\boldsymbol{z = \\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j}}$ <br>\n",
    "Now, using $z$ and plugging in the two simplified expressions from above, we obtain:\n",
    "$$\n",
    "L=-\\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left(y_{i, j} \\log \\left(\\sigma\\left(z\\right)\\right)+\\left(1-y_{i, j}\\right) \\log \\left(1-\\sigma\\left(z\\right)\\right)\\right) \\newline\n",
    "=-\\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left(-1 \\cdot y_{i, j} \\log(1+e^{-z}) +\\left(1-y_{i, j}\\right) \n",
    "\\left( -(z + \\log(1+e^{-z}))\\right)\\right) \\newline\n",
    "=-\\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left(-1 \\cdot y_{i, j} \\log(1+e^{-z}) - \\left(1-y_{i, j}\\right)(z + \\log(1+e^{-z})) \\right) \\newline\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left(y_{i, j} \\log(1+e^{-z}) + \\left(1-y_{i, j}\\right)(z + \\log(1+e^{-z})) \\right) \\newline\n",
    "$$\n",
    "\n",
    "After opening up the multiplications, we end up with:\n",
    "$$\n",
    "L= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j}\\left( z - y_{i, j} z + \\log(1+e^{-z}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "- Reference: https://math.stackexchange.com/questions/477207/derivative-of-cost-function-for-logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need now is to compute the partial derivatives of $L$ w.r.t the user and item latent vector weights ($u_i,  v_j$), the global bias ($\\mu$), user bias ($p_i$) and item bias ($o_j$) variables for user i and item j.<br>\n",
    "The update rules are:\n",
    "$$\n",
    "u = u - \\frac{\\partial L}{\\partial u} \\newline\n",
    "v = v - \\frac{\\partial L}{\\partial v} \\newline\n",
    "\\mu = \\mu - \\frac{\\partial L}{\\partial \\mu} \\newline\n",
    "p = p - \\frac{\\partial L}{\\partial p} \\newline\n",
    "o = o - \\frac{\\partial L}{\\partial o}\n",
    "$$\n",
    "\n",
    "Using the \"Chain Rule\" - we solve each derivative separately and then plug back in:\n",
    "\n",
    "\n",
    "- **user latent vector weights ($u_i$):**\n",
    "$$\n",
    "\\frac{\\partial [\\alpha_{j} z]}{\\partial u_i}\n",
    "= \\frac{\\partial [\\alpha_{j} (\\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j})]}{\\partial u_i} \n",
    "= \\alpha_{j} v_{j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial [-\\alpha_{j}  y_{i, j} z]}{\\partial u_i}\n",
    "= \\frac{\\partial [- \\alpha_{j} y_{i, j}(\\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j})]} {\\partial u_i} \n",
    "= -\\alpha_{j} y_{i, j} v_{j}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial [\\alpha_{j}  \\log(1+e^{-z})]}{\\partial u_i}\n",
    "= \\frac{\\alpha_j e^{-z} \\frac{\\partial z}{\\partial u_i}} {1 + e^{-z}}\n",
    "= - \\frac{\\alpha_{j} e^{-z} v_{j}}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "* (Last transition, log derivative, follows from [here](https://www.symbolab.com/solver/step-by-step/%5Cleft(log_%7Be%7D%5Cleft(1%2Be%5E%7B-2x%7D%5Cright)%5Cright)%5E%7B'%7D))\n",
    "\n",
    "Hence,\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial u_i}\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\big( \\alpha_{j} v_{j} - \\alpha_{j} y_{i, j} v_{j} - \\frac{\\alpha_{j} e^{-z} v_{j}}{1 + e^{-z}} \\big) \n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j} v_{j} \\big( 1 - y_{i, j} - \\frac{e^{-z}}{1 + e^{-z}} \\big) \n",
    "$$\n",
    "\n",
    "\n",
    "- **item latent vector weights ($v_j$)** is very similar, since both terms are multiplied with each other:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial v_j}\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\big( \\alpha_{j} {u}_{i}^{T} - \\alpha_{j} y_{i, j} {u}_{i}^{T} - \\frac{\\alpha_{j} e^{-z} {u}_{i}^{T}}{1 + e^{-z}} \\big) \n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j} {u}_{i}^{T} \\big( 1 - y_{i, j} - \\frac{e^{-z}}{1 + e^{-z}} \\big) \n",
    "$$\n",
    "\n",
    "\n",
    "- **the global bias, $\\mu$:**\n",
    "$$\n",
    "\\frac{\\partial [\\alpha_{j} z]}{\\partial \\mu}\n",
    "= \\frac{\\partial [\\alpha_{j} (\\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j})]}{\\partial \\mu} \n",
    "= \\alpha_{j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial [-\\alpha_{j}  y_{i, j} z]}{\\partial \\mu}\n",
    "= \\frac{\\partial [- \\alpha_{j} y_{i, j}(\\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j})]} {\\partial \\mu} \n",
    "= -\\alpha_{j} y_{i, j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial [\\alpha_{j}  \\log(1+e^{-z})]}{\\partial \\mu}\n",
    "= \\frac{\\partial [\\alpha_{j} \\log(1 + e^{\\mu+p_{i}+o_{j}+{u}_{i}^{T} v_{j}})]} {\\partial \\mu} \n",
    "= \\frac{\\alpha_j e^{-z} \\frac{\\partial z}{\\partial u_i}} {1 + e^{-z}}\n",
    "= - \\frac{\\alpha_{j} e^{-z}}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Hence,\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mu}\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\big( \\alpha_{j} - \\alpha_{j} y_{i, j} - \\frac{\\alpha_{j} e^{-z}}{1 + e^{-z}} \\big) \n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j} \\big( 1 - y_{i, j} - \\frac{e^{-z}}{1 + e^{-z}} \\big) \n",
    "$$\n",
    "\n",
    "\n",
    "- **user bias $p_i$** follows the same calculation as $\\mu$ since it's added as a standalone addition:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial p_i}\n",
    "= \\frac{\\partial L}{\\partial \\mu}\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j} \\big( 1 - y_{i, j} - \\frac{e^{-z}}{1 + e^{-z}} \\big) \n",
    "$$\n",
    "\n",
    "\n",
    "- **item bias $o_j$** follows the same calculation as $\\mu$ since it's added as a standalone addition:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial o_j}\n",
    "= \\frac{\\partial L}{\\partial \\mu}\n",
    "= \\frac{1}{N} \\sum_{(i, j) \\in S}^{N} \\alpha_{j} \\big( 1 - y_{i, j} - \\frac{e^{-z}}{1 + e^{-z}} \\big) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Answer:\n",
    "\n",
    "Given the prices of the different items from the catalog, we can set the weights for each training instance based on the **item price divided by the maximal price** we have.\n",
    "Meaning, we're giving each weight its relative \"significance\".\n",
    "\n",
    "This is very intuitive and straightforward - The more expensive an item is, the larger weight it's given, where weights' values range from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 2: Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A) Use the item_price.csv file to get the prices of each item. Explore the price distribution of items.\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3706 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price\n",
       "item       \n",
       "0         4\n",
       "1         1\n",
       "2         1\n",
       "3         2\n",
       "4         2\n",
       "...     ...\n",
       "3701     25\n",
       "3702      4\n",
       "3703      1\n",
       "3704      4\n",
       "3705      4\n",
       "\n",
       "[3706 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_price = pd.read_csv('./item_price.csv')\n",
    "item_price.set_index('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_items = item_price.shape[0]\n",
    "prices = item_price['price']\n",
    "min_price = prices.min()\n",
    "max_price = prices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x138ace070>,\n",
       "  <matplotlib.axis.XTick at 0x138ace040>,\n",
       "  <matplotlib.axis.XTick at 0x138a72670>,\n",
       "  <matplotlib.axis.XTick at 0x138bb2d30>,\n",
       "  <matplotlib.axis.XTick at 0x138bc4280>],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(item_price.price, align='mid', bins=50)\n",
    "plt.xticks(item_price.price.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price\n",
       "1     1326\n",
       "2      896\n",
       "4      709\n",
       "9      589\n",
       "25     186\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_price.groupby('price')['item'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3706.000000</td>\n",
       "      <td>3706.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1852.500000</td>\n",
       "      <td>4.291689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1069.974377</td>\n",
       "      <td>5.496992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>926.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1852.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2778.750000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3705.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item        price\n",
       "count  3706.000000  3706.000000\n",
       "mean   1852.500000     4.291689\n",
       "std    1069.974377     5.496992\n",
       "min       0.000000     1.000000\n",
       "25%     926.250000     1.000000\n",
       "50%    1852.500000     2.000000\n",
       "75%    2778.750000     4.000000\n",
       "max    3705.000000    25.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3706 items with prices distributed from [1, 2, 4, 9, 25].<br>\n",
    "From the histogram and the data we see that most of the items are priced 2 and lower - ((1: 1326), (2: 896), (4: 709), (9: 589), (25: 186))<br>\n",
    "It doesn't look like we can deduce a behaviour of a specific distribution (like normal/uniform etc.), especially since we don't have enough data other than ID numbers and prices...<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B) To evaluate the performance of the price sensitive model we add another metric Revenue@K which measures the overall revenue from the top 5 recommended hits.\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3696</th>\n",
       "      <th>3697</th>\n",
       "      <th>3698</th>\n",
       "      <th>3699</th>\n",
       "      <th>3700</th>\n",
       "      <th>3701</th>\n",
       "      <th>3702</th>\n",
       "      <th>3703</th>\n",
       "      <th>3704</th>\n",
       "      <th>3705</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5761</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  3696  \\\n",
       "5099   5.0   5.0   5.0   0.0   5.0   5.0   4.0   4.0   5.0   5.0  ...   0.0   \n",
       "5761   5.0   5.0   5.0   0.0   5.0   0.0   5.0   0.0   4.0   5.0  ...   0.0   \n",
       "52     5.0   5.0   5.0   0.0   5.0   0.0   0.0   0.0   5.0   5.0  ...   0.0   \n",
       "4509   5.0   5.0   5.0   0.0   3.0   3.0   3.0   4.0   4.0   3.0  ...   0.0   \n",
       "423    5.0   5.0   4.0   5.0   5.0   5.0   5.0   4.0   5.0   5.0  ...   0.0   \n",
       "\n",
       "      3697  3698  3699  3700  3701  3702  3703  3704  3705  \n",
       "5099   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5761   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "52     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4509   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "423    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for idx, row in enumerate(rating_train):\n",
    "#     print(row.shape)\n",
    "x = pd.DataFrame(rating_train)\n",
    "x.nlargest(5, columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.34023178807947\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def revenue_at_K(ratings, item_price, K=5):\n",
    "    ''' \n",
    "    For each user: sum the prices of the top K recommended items which were rated as the revenue from the user \n",
    "    Calculate the mean revenue from all users \n",
    "    '''\n",
    "    row_sums = []\n",
    "    for row in ratings:\n",
    "        top_k_items = list(row.argsort()[-5:][::-1])\n",
    "        row_sums.append(sum(list(item_price[item_price.item.isin(top_k_items)].price)))\n",
    "    return np.mean(row_sums)\n",
    "\n",
    "\n",
    "# Calculate the mean revenue from all users\n",
    "print(revenue_at_K(rating_train, item_price, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C) Suggest a metric of your own which will incorporate both the ranking of the recommended items as well as its price. Explain why this metric is suitable and demonstrate it as part of the evaluation in point e below.\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-K NDCG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D) Select one of the models presented in the Neural Collaborative Filtering paper and incorporate the movie price to the loss function as part of training\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, regs=None, activation='sigmoid'):\n",
    "    '''Generalized Matrix Factorization'''\n",
    "\n",
    "    if not regs:\n",
    "        regs = [[0,0]]\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings \n",
    "    predict_vector = Multiply()([user_latent, item_latent]) #merge([user_latent, item_latent], mode = 'mul')\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation=activation, kernel_initializer='lecun_uniform', name = 'prediction')(predict_vector)\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model():\n",
    "    gmf_model = get_GMF_model(num_users, num_items, num_factors, regs = [[0,0]])\n",
    "    gmf_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
    "   \n",
    "    return gmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M7nlDtDaCakQ"
   },
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [0]*((num_negatives + 1)*len(train)),[0]*((num_negatives + 1)*len(train)),[1]\n",
    "    num_users = train.shape[0]\n",
    "    all_items = training.item_id.unique().argsort()\n",
    "    \n",
    "    negatives = [0]*num_negatives\n",
    "    labels.extend(negatives)\n",
    "    total_labels = []\n",
    "    list(map(lambda x: total_labels.extend(labels), range(len(train))))\n",
    "#     return\n",
    "    percent_1 = int(len(train)/100)\n",
    "    ic(percent_1)\n",
    "    \n",
    "    items_the_user_didnt_rank = None\n",
    "    prev_user = -1\n",
    "    chosen_item_per_user = []\n",
    "    for idx_i in range(len(train)):\n",
    "        curr_index = idx_i * (num_negatives + 1)\n",
    "        if idx_i != 0 and idx_i % percent_1 == 0:\n",
    "            print(f'{int(idx_i/percent_1)}%')\n",
    "        u = train.iloc[idx_i].user_id\n",
    "        i = train.iloc[idx_i].item_id\n",
    "\n",
    "        user_input[curr_index:curr_index + (num_negatives + 1)] = [u]*(num_negatives + 1)\n",
    "\n",
    "        item_input[curr_index] = i\n",
    "        \n",
    "        if u != prev_user:\n",
    "            items = training[training['user_id'] == u].item_id.to_numpy().argsort()\n",
    "            items_the_user_didnt_rank = all_items[~np.in1d(all_items,items)]\n",
    "            prev_user = u\n",
    "#             chosen_item_per_user = []\n",
    "\n",
    "#         items_the_user_didnt_rank = items_the_user_didnt_rank[~np.in1d(items_the_user_didnt_rank,chosen_item_per_user)]\n",
    "        sample_items = items_the_user_didnt_rank[np.random.choice(len(items_the_user_didnt_rank), size=num_negatives, replace=False)]\n",
    "        item_input[curr_index+1:curr_index + (num_negatives + 1)] = sample_items\n",
    "#         chosen_item_per_user.extend(sample_items)\n",
    "\n",
    "    return user_input, item_input, total_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E) Compare the results of the original model and the one with the customized loss across the four metrics: (20 points)** \n",
    "- MRR@5\n",
    "- NDCG@5\n",
    "- Revenue@5 \n",
    "- your custom metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- Compare between different heuristics of item price to weights mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- Present the comparison results, discuss the results and the trade-offs and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- Compare between different heuristics of item price to weights mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "- Verify and present that the learning is ‘healthy’ (no overfitting, no under-fitting and that the results make sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 3: Loss function\n",
    "Cold start or users\\items with a small number of interactions is a very common scenario in real world. In this question you will plan how you can leverage content based features to handle the cold start scenario.\n",
    "\n",
    "\n",
    "A) Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
