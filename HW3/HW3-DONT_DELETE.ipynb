{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations Systems\n",
    "## Homework 3: Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution in the form of an Jupyter notebook file (with extension ipynb).   \n",
    "Images of graphs or tables should be submitted as PNG or JPG files.   \n",
    "The code used to answer the questions should be included, runnable and documented in the notebook.   \n",
    "Python 3.6 should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to let you understand the concept of  recommendations based on implicit data which is very common in real life, and learn how ‘Deep neural networks’ components can be used to implement a collaborative filtering and hybrid approach recommenders.  \n",
    "Implementation example is presented in the <a href='https://colab.research.google.com/drive/1v72_zpCObTFMbNnQXUknoQVXR1vBRX6_?usp=sharing'>NeuralCollaborativeFiltering_Implicit</a> notebook in Moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a dataset based on the <a href='https://grouplens.org/datasets/movielens/1m/'>MovieLens 1M rating dataset</a> after some pre-processing to adapt it to an implicit feedback use case scenario.  \n",
    "You can download the dataset used by <a href='https://github.com/hexiangnan/neural_collaborative_filtering'>this implementation</a> of the paper Neural Collaborative Filtering or from the NeuralCollaborativeFiltering_implicit notebook in Moodle.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense, Reshape,  Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from keras.layers import Multiply, Concatenate\n",
    "\n",
    "# from time import time\n",
    "# import multiprocessing as mp\n",
    "# import sys\n",
    "# import math\n",
    "# import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negatives = 4\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hexiangnan/neural_collaborative_filtering.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "# Read the training file\n",
    "training = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.train.rating', sep='\\t', names=column_names)\n",
    "\n",
    "# Read the test file\n",
    "test_rating = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.rating', sep='\\t', names=column_names)\n",
    "\n",
    "\n",
    "negative_ids = ['(user_id, item_id)']\n",
    "\n",
    "for i in range(1,100):\n",
    "    negative_ids.append(f'id-{i}')\n",
    "\n",
    "test_negative = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.negative', sep='\\t', names=negative_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  rating  timestamp\n",
       "13        0        8       4  978302268"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.loc[(training['user_id'] == 0) & (training['item_id'] == 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. This implementation contains one file for training and two files for testing:\n",
    "- ml-1m.train.rating\n",
    "- ml-1m.test.rating\n",
    "- ml-1m.test.negative\n",
    "\n",
    "**Explain** the role and structure of each file and how it was created from the original MovieLens 1M rating dataset.\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ml-1m.train.rating:\n",
    "- Training file\n",
    "- Each line is a training instance: userID\\t itemID\\t rating\\t timestamp (if exists)\n",
    "- 1 million ratings, where each user has at least 20 ratings\n",
    "- Similar to the training data from previous HWs\n",
    "\n",
    "ml-1m.test.rating:\n",
    "- Test file (positive instances)\n",
    "- Each line is a testing instance: userID\\t itemID\\t rating\\t timestamp (if exists)\n",
    "\n",
    "ml-1m.test.negative:\n",
    "- Test file (negative instances)\n",
    "- Each line corresponds to the line of test.rating, containing 99 negative samples\n",
    "- Each line is in the format: (userID,itemID)\\t negativeItemID1\\t negativeItemID2..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **Explain** how the training dataset is created.\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. **Explain** how the test dataset is created.\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 2: Neural Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "M7nlDtDaCakQ"
   },
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [0]*((num_negatives + 1)*len(train)),[0]*((num_negatives + 1)*len(train)),[1]\n",
    "    num_users = train.shape[0]\n",
    "    all_items = training.item_id.unique().argsort()\n",
    "    \n",
    "    negatives = [0]*num_negatives\n",
    "    labels.extend(negatives)\n",
    "    total_labels = []\n",
    "    list(map(lambda x: total_labels.extend(labels), range(len(train))))\n",
    "#     return\n",
    "    percent_1 = int(len(train)/100)\n",
    "    ic(percent_1)\n",
    "    \n",
    "    items_the_user_didnt_rank = None\n",
    "    prev_user = -1\n",
    "    chosen_item_per_user = []\n",
    "    for idx_i in range(len(train)):\n",
    "        curr_index = idx_i * (num_negatives + 1)\n",
    "        if idx_i != 0 and idx_i % percent_1 == 0:\n",
    "            print(f'{int(idx_i/percent_1)}%')\n",
    "        u = train.iloc[idx_i].user_id\n",
    "        i = train.iloc[idx_i].item_id\n",
    "\n",
    "        user_input[curr_index:curr_index + (num_negatives + 1)] = [u]*(num_negatives + 1)\n",
    "\n",
    "        item_input[curr_index] = i\n",
    "        \n",
    "        if u != prev_user:\n",
    "            items = training[training['user_id'] == u].item_id.to_numpy().argsort()\n",
    "            items_the_user_didnt_rank = all_items[~np.in1d(all_items,items)]\n",
    "            prev_user = u\n",
    "#             chosen_item_per_user = []\n",
    "\n",
    "#         items_the_user_didnt_rank = items_the_user_didnt_rank[~np.in1d(items_the_user_didnt_rank,chosen_item_per_user)]\n",
    "        sample_items = items_the_user_didnt_rank[np.random.choice(len(items_the_user_didnt_rank), size=num_negatives, replace=False)]\n",
    "        item_input[curr_index+1:curr_index + (num_negatives + 1)] = sample_items\n",
    "#         chosen_item_per_user.extend(sample_items)\n",
    "\n",
    "    return user_input, item_input, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| percent_1: 9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n",
      "100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| time() - start: 238.94894123077393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "238.94894123077393"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "training_data = get_train_instances(training, num_negatives)\n",
    "ic(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input, item_input, total_labels = training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "training_data_df = pd.DataFrame(list(zip(user_input, item_input, total_labels)), \n",
    "               columns =['user_input', 'item_input', 'total_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.to_csv('training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Build the following four models using the neural collaborative filtering approach: \n",
    "- Matrix Factorization (MF)\n",
    "- Multi layer perceptron (MLP)\n",
    "- Generalized Matrix Factorization (GMF) \n",
    "- NeuroMatrixFactorization (NMF)\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Matrix Factorization (from previous HWs?)\n",
    "# no need to use it in the assignment anyway. see 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, regs=None, activation='sigmoid'):\n",
    "    if not regs:\n",
    "        regs = [[0,0]]\n",
    "    # Generalized Matrix Factorization\n",
    "    \n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings \n",
    "    predict_vector = Multiply()([user_latent, item_latent]) #merge([user_latent, item_latent], mode = 'mul')\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation=activation, kernel_initializer='lecun_uniform', name = 'prediction')(predict_vector)\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_MLP_model(num_users, num_items, latent_dim, regs=None, layers = None, activation='sigmoid'):\n",
    "    if not regs:\n",
    "        regs = [[0,0],0,0]\n",
    "    if not layers:\n",
    "        layers = [20,10]\n",
    "    # Multi-Layer Perceptron\n",
    "    \n",
    "    assert len(layers) + 1 == len(regs), 'the number of regs is equal to number of layers + the embedding layer'\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\n",
    "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
    "    \n",
    "    # Concatenation of embedding layers\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])#merge([user_latent, item_latent], mode = 'concat')\n",
    "    \n",
    "    # MLP layers\n",
    "    for idx in range(num_layer):\n",
    "        layer = Dense(layers[idx], kernel_regularizer = l2(regs[idx+1]), activation='relu', name = 'layer%d' %idx)\n",
    "        vector = layer(vector)\n",
    "        \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation=activation, kernel_initializer='lecun_uniform', name = 'prediction')(vector)\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_NMF_model(num_users, num_items, latent_dim_GMF, latent_dim_MLP, reg_GMF=None, regs_MLP=None, layers=None, activation='sigmoid'):\n",
    "    if not reg_GMF:\n",
    "        reg_GMF=[[0,0]]\n",
    "    if not regs_MLP:\n",
    "        regs_MLP=[[0,0],0,0]\n",
    "    if not layers:\n",
    "        layers=[20,10]\n",
    "    # Neural matrix factorization\n",
    "    assert len(layers) + 1 == len(regs_MLP), 'the number of regs is equal to number of layers + the embedding layer'\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_GMF, name = 'MF_user_embedding',\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_GMF, name = 'MF_item_embedding',\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \n",
    "    \n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_MLP, name = 'MLP_user_embedding',\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_MLP, name = 'MLP_item_embedding',\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\n",
    "    \n",
    "    # MF part\n",
    "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) #merge([mf_user_latent, mf_item_latent], mode = 'mul') # element-wise multiply\n",
    "\n",
    "    # MLP part\n",
    "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
    "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])#merge([mlp_user_latent, mlp_item_latent], mode = 'concat')\n",
    "    \n",
    "    for idx in range(num_layer):\n",
    "        layer =  Dense(layers[idx], kernel_regularizer = l2(regs_MLP[idx+1]), activation='tanh', name = 'layer%d' %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    # Concatenate MF and MLP parts\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation=activation, kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 8 #size of embedding size. Can be split to 4 different params potentially.\n",
    "num_negatives = 4 #how many negative samples per positive sample?\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "verbose = 1\n",
    "\n",
    "topK = 10 #used to evaluate the model. Top K recommendations are used. \n",
    "num_users = len(training_data_df.user_input.unique())\n",
    "num_items = len(training_data_df.item_input.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models\n",
    "mlp_model = get_MLP_model(num_users, num_items, num_factors, regs = [[0,0],0,0,0], layers = [32,16,8])\n",
    "gmf_model = get_GMF_model(num_users, num_items, num_factors, regs = [[0,0]])\n",
    "nmf_model = get_NMF_model(num_users, num_items, latent_dim_GMF=num_factors, latent_dim_MLP=num_factors, reg_GMF=[[0,0]], regs_MLP=[[0,0],0,0,0], layers=[32,16,8])\n",
    "\n",
    "mlp_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
    "gmf_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
    "nmf_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train and evaluate the recommendations accuracy of three models: \n",
    "- MF or GMF\n",
    "- MLP\n",
    "- NMF\n",
    "\n",
    "Compare the learning curve and recommendations accuracy using NDCG and MRR metrics with cutoff values of 5 and 10.   \n",
    "Discuss the comparison.\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phL8meRGnql2"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "from time import time\n",
    "#from numba import jit, autojit\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_ratings, test_negatives, K):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (MRR, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    mrrs, ndcgs = zip(*[eval_one_rating(model, test_ratings, test_negatives, idx, K) for idx in range(len(test_ratings))])\n",
    "    return np.array(mrrs).mean(), np.array(ndcgs).mean()\n",
    "\n",
    "\n",
    "def eval_one_rating(model, test_ratings, test_negatives, idx, K):\n",
    "    u = test_ratings.iloc[idx].user_id\n",
    "    gtItem = test_ratings.iloc[idx].item_id\n",
    "    items = test_negatives[test_negatives['(user_id, item_id)'] == f'({u},{gtItem})'].to_numpy()[0]\n",
    "    items = items[1:len(items)].astype('int32')\n",
    "    items = np.append(items, gtItem)\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    predictions = model.predict([users, np.array(items)], \n",
    "                                 batch_size=100, verbose=0)\n",
    "    \n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    \n",
    "    items = items[:len(items)-1]\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(K, map_item_score, key=map_item_score.get)\n",
    "    mrr = getMRR(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    \n",
    "    return mrr, ndcg\n",
    "\n",
    "\n",
    "def getMRR(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        \n",
    "        if item == gtItem:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        \n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       25       5  978824351\n",
       "1        1      133       3  978300174\n",
       "2        2      207       4  978298504\n",
       "3        3      208       4  978294282\n",
       "4        4      222       2  978246585"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(user_id, item_id)</th>\n",
       "      <th>id-1</th>\n",
       "      <th>id-2</th>\n",
       "      <th>id-3</th>\n",
       "      <th>id-4</th>\n",
       "      <th>id-5</th>\n",
       "      <th>id-6</th>\n",
       "      <th>id-7</th>\n",
       "      <th>id-8</th>\n",
       "      <th>id-9</th>\n",
       "      <th>id-10</th>\n",
       "      <th>id-11</th>\n",
       "      <th>id-12</th>\n",
       "      <th>id-13</th>\n",
       "      <th>id-14</th>\n",
       "      <th>id-15</th>\n",
       "      <th>id-16</th>\n",
       "      <th>id-17</th>\n",
       "      <th>id-18</th>\n",
       "      <th>id-19</th>\n",
       "      <th>id-20</th>\n",
       "      <th>id-21</th>\n",
       "      <th>id-22</th>\n",
       "      <th>id-23</th>\n",
       "      <th>id-24</th>\n",
       "      <th>id-25</th>\n",
       "      <th>id-26</th>\n",
       "      <th>id-27</th>\n",
       "      <th>id-28</th>\n",
       "      <th>id-29</th>\n",
       "      <th>id-30</th>\n",
       "      <th>id-31</th>\n",
       "      <th>id-32</th>\n",
       "      <th>id-33</th>\n",
       "      <th>id-34</th>\n",
       "      <th>id-35</th>\n",
       "      <th>id-36</th>\n",
       "      <th>id-37</th>\n",
       "      <th>id-38</th>\n",
       "      <th>id-39</th>\n",
       "      <th>id-40</th>\n",
       "      <th>id-41</th>\n",
       "      <th>id-42</th>\n",
       "      <th>id-43</th>\n",
       "      <th>id-44</th>\n",
       "      <th>id-45</th>\n",
       "      <th>id-46</th>\n",
       "      <th>id-47</th>\n",
       "      <th>id-48</th>\n",
       "      <th>id-49</th>\n",
       "      <th>id-50</th>\n",
       "      <th>id-51</th>\n",
       "      <th>id-52</th>\n",
       "      <th>id-53</th>\n",
       "      <th>id-54</th>\n",
       "      <th>id-55</th>\n",
       "      <th>id-56</th>\n",
       "      <th>id-57</th>\n",
       "      <th>id-58</th>\n",
       "      <th>id-59</th>\n",
       "      <th>id-60</th>\n",
       "      <th>id-61</th>\n",
       "      <th>id-62</th>\n",
       "      <th>id-63</th>\n",
       "      <th>id-64</th>\n",
       "      <th>id-65</th>\n",
       "      <th>id-66</th>\n",
       "      <th>id-67</th>\n",
       "      <th>id-68</th>\n",
       "      <th>id-69</th>\n",
       "      <th>id-70</th>\n",
       "      <th>id-71</th>\n",
       "      <th>id-72</th>\n",
       "      <th>id-73</th>\n",
       "      <th>id-74</th>\n",
       "      <th>id-75</th>\n",
       "      <th>id-76</th>\n",
       "      <th>id-77</th>\n",
       "      <th>id-78</th>\n",
       "      <th>id-79</th>\n",
       "      <th>id-80</th>\n",
       "      <th>id-81</th>\n",
       "      <th>id-82</th>\n",
       "      <th>id-83</th>\n",
       "      <th>id-84</th>\n",
       "      <th>id-85</th>\n",
       "      <th>id-86</th>\n",
       "      <th>id-87</th>\n",
       "      <th>id-88</th>\n",
       "      <th>id-89</th>\n",
       "      <th>id-90</th>\n",
       "      <th>id-91</th>\n",
       "      <th>id-92</th>\n",
       "      <th>id-93</th>\n",
       "      <th>id-94</th>\n",
       "      <th>id-95</th>\n",
       "      <th>id-96</th>\n",
       "      <th>id-97</th>\n",
       "      <th>id-98</th>\n",
       "      <th>id-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0,25)</td>\n",
       "      <td>1064</td>\n",
       "      <td>174</td>\n",
       "      <td>2791</td>\n",
       "      <td>3373</td>\n",
       "      <td>269</td>\n",
       "      <td>2678</td>\n",
       "      <td>1902</td>\n",
       "      <td>3641</td>\n",
       "      <td>1216</td>\n",
       "      <td>915</td>\n",
       "      <td>3672</td>\n",
       "      <td>2803</td>\n",
       "      <td>2344</td>\n",
       "      <td>986</td>\n",
       "      <td>3217</td>\n",
       "      <td>2824</td>\n",
       "      <td>2598</td>\n",
       "      <td>464</td>\n",
       "      <td>2340</td>\n",
       "      <td>1952</td>\n",
       "      <td>1855</td>\n",
       "      <td>1353</td>\n",
       "      <td>1547</td>\n",
       "      <td>3487</td>\n",
       "      <td>3293</td>\n",
       "      <td>1541</td>\n",
       "      <td>2414</td>\n",
       "      <td>2728</td>\n",
       "      <td>340</td>\n",
       "      <td>1421</td>\n",
       "      <td>1963</td>\n",
       "      <td>2545</td>\n",
       "      <td>972</td>\n",
       "      <td>487</td>\n",
       "      <td>3463</td>\n",
       "      <td>2727</td>\n",
       "      <td>1135</td>\n",
       "      <td>3135</td>\n",
       "      <td>128</td>\n",
       "      <td>175</td>\n",
       "      <td>2423</td>\n",
       "      <td>1974</td>\n",
       "      <td>2515</td>\n",
       "      <td>3278</td>\n",
       "      <td>3079</td>\n",
       "      <td>1527</td>\n",
       "      <td>2182</td>\n",
       "      <td>1018</td>\n",
       "      <td>2800</td>\n",
       "      <td>1830</td>\n",
       "      <td>1539</td>\n",
       "      <td>617</td>\n",
       "      <td>247</td>\n",
       "      <td>3448</td>\n",
       "      <td>1699</td>\n",
       "      <td>1420</td>\n",
       "      <td>2487</td>\n",
       "      <td>198</td>\n",
       "      <td>811</td>\n",
       "      <td>1010</td>\n",
       "      <td>1423</td>\n",
       "      <td>2840</td>\n",
       "      <td>1770</td>\n",
       "      <td>881</td>\n",
       "      <td>1913</td>\n",
       "      <td>1803</td>\n",
       "      <td>1734</td>\n",
       "      <td>3326</td>\n",
       "      <td>1617</td>\n",
       "      <td>224</td>\n",
       "      <td>3352</td>\n",
       "      <td>1869</td>\n",
       "      <td>1182</td>\n",
       "      <td>1331</td>\n",
       "      <td>336</td>\n",
       "      <td>2517</td>\n",
       "      <td>1721</td>\n",
       "      <td>3512</td>\n",
       "      <td>3656</td>\n",
       "      <td>273</td>\n",
       "      <td>1026</td>\n",
       "      <td>1991</td>\n",
       "      <td>2190</td>\n",
       "      <td>998</td>\n",
       "      <td>3386</td>\n",
       "      <td>3369</td>\n",
       "      <td>185</td>\n",
       "      <td>2822</td>\n",
       "      <td>864</td>\n",
       "      <td>2854</td>\n",
       "      <td>3067</td>\n",
       "      <td>58</td>\n",
       "      <td>2551</td>\n",
       "      <td>2333</td>\n",
       "      <td>2688</td>\n",
       "      <td>3703</td>\n",
       "      <td>1300</td>\n",
       "      <td>1924</td>\n",
       "      <td>3118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1,133)</td>\n",
       "      <td>1072</td>\n",
       "      <td>3154</td>\n",
       "      <td>3368</td>\n",
       "      <td>3644</td>\n",
       "      <td>549</td>\n",
       "      <td>1810</td>\n",
       "      <td>937</td>\n",
       "      <td>1514</td>\n",
       "      <td>1713</td>\n",
       "      <td>2186</td>\n",
       "      <td>660</td>\n",
       "      <td>2303</td>\n",
       "      <td>2416</td>\n",
       "      <td>670</td>\n",
       "      <td>1176</td>\n",
       "      <td>788</td>\n",
       "      <td>889</td>\n",
       "      <td>3120</td>\n",
       "      <td>2344</td>\n",
       "      <td>2525</td>\n",
       "      <td>3301</td>\n",
       "      <td>2055</td>\n",
       "      <td>1436</td>\n",
       "      <td>2630</td>\n",
       "      <td>11</td>\n",
       "      <td>2773</td>\n",
       "      <td>2176</td>\n",
       "      <td>1847</td>\n",
       "      <td>740</td>\n",
       "      <td>2332</td>\n",
       "      <td>3561</td>\n",
       "      <td>263</td>\n",
       "      <td>3658</td>\n",
       "      <td>3282</td>\n",
       "      <td>1980</td>\n",
       "      <td>2093</td>\n",
       "      <td>3287</td>\n",
       "      <td>3190</td>\n",
       "      <td>3475</td>\n",
       "      <td>569</td>\n",
       "      <td>2315</td>\n",
       "      <td>1442</td>\n",
       "      <td>592</td>\n",
       "      <td>546</td>\n",
       "      <td>3133</td>\n",
       "      <td>1852</td>\n",
       "      <td>2648</td>\n",
       "      <td>934</td>\n",
       "      <td>337</td>\n",
       "      <td>483</td>\n",
       "      <td>1017</td>\n",
       "      <td>3452</td>\n",
       "      <td>467</td>\n",
       "      <td>1183</td>\n",
       "      <td>1765</td>\n",
       "      <td>601</td>\n",
       "      <td>2413</td>\n",
       "      <td>2602</td>\n",
       "      <td>2801</td>\n",
       "      <td>2976</td>\n",
       "      <td>918</td>\n",
       "      <td>753</td>\n",
       "      <td>3540</td>\n",
       "      <td>3341</td>\n",
       "      <td>2973</td>\n",
       "      <td>1580</td>\n",
       "      <td>2118</td>\n",
       "      <td>3511</td>\n",
       "      <td>526</td>\n",
       "      <td>1719</td>\n",
       "      <td>525</td>\n",
       "      <td>1520</td>\n",
       "      <td>486</td>\n",
       "      <td>557</td>\n",
       "      <td>1353</td>\n",
       "      <td>500</td>\n",
       "      <td>2902</td>\n",
       "      <td>1687</td>\n",
       "      <td>1295</td>\n",
       "      <td>2997</td>\n",
       "      <td>2415</td>\n",
       "      <td>797</td>\n",
       "      <td>2518</td>\n",
       "      <td>926</td>\n",
       "      <td>3537</td>\n",
       "      <td>1746</td>\n",
       "      <td>1676</td>\n",
       "      <td>1875</td>\n",
       "      <td>3029</td>\n",
       "      <td>1535</td>\n",
       "      <td>341</td>\n",
       "      <td>3525</td>\n",
       "      <td>1429</td>\n",
       "      <td>2225</td>\n",
       "      <td>1628</td>\n",
       "      <td>2061</td>\n",
       "      <td>469</td>\n",
       "      <td>3056</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2,207)</td>\n",
       "      <td>2216</td>\n",
       "      <td>209</td>\n",
       "      <td>2347</td>\n",
       "      <td>3</td>\n",
       "      <td>1652</td>\n",
       "      <td>3397</td>\n",
       "      <td>383</td>\n",
       "      <td>2905</td>\n",
       "      <td>2284</td>\n",
       "      <td>2866</td>\n",
       "      <td>584</td>\n",
       "      <td>783</td>\n",
       "      <td>3208</td>\n",
       "      <td>1534</td>\n",
       "      <td>2529</td>\n",
       "      <td>1907</td>\n",
       "      <td>1170</td>\n",
       "      <td>3037</td>\n",
       "      <td>2015</td>\n",
       "      <td>1045</td>\n",
       "      <td>3099</td>\n",
       "      <td>3298</td>\n",
       "      <td>2522</td>\n",
       "      <td>739</td>\n",
       "      <td>2652</td>\n",
       "      <td>3702</td>\n",
       "      <td>792</td>\n",
       "      <td>2527</td>\n",
       "      <td>1945</td>\n",
       "      <td>2333</td>\n",
       "      <td>1668</td>\n",
       "      <td>3511</td>\n",
       "      <td>70</td>\n",
       "      <td>1991</td>\n",
       "      <td>3071</td>\n",
       "      <td>2474</td>\n",
       "      <td>1629</td>\n",
       "      <td>3221</td>\n",
       "      <td>505</td>\n",
       "      <td>3266</td>\n",
       "      <td>1475</td>\n",
       "      <td>515</td>\n",
       "      <td>2704</td>\n",
       "      <td>1717</td>\n",
       "      <td>569</td>\n",
       "      <td>3248</td>\n",
       "      <td>241</td>\n",
       "      <td>2643</td>\n",
       "      <td>2137</td>\n",
       "      <td>2336</td>\n",
       "      <td>2627</td>\n",
       "      <td>2618</td>\n",
       "      <td>2748</td>\n",
       "      <td>2967</td>\n",
       "      <td>2579</td>\n",
       "      <td>1732</td>\n",
       "      <td>3283</td>\n",
       "      <td>1440</td>\n",
       "      <td>1052</td>\n",
       "      <td>1906</td>\n",
       "      <td>1812</td>\n",
       "      <td>1182</td>\n",
       "      <td>2831</td>\n",
       "      <td>1548</td>\n",
       "      <td>1630</td>\n",
       "      <td>2227</td>\n",
       "      <td>2352</td>\n",
       "      <td>760</td>\n",
       "      <td>350</td>\n",
       "      <td>302</td>\n",
       "      <td>791</td>\n",
       "      <td>300</td>\n",
       "      <td>3528</td>\n",
       "      <td>1444</td>\n",
       "      <td>2</td>\n",
       "      <td>798</td>\n",
       "      <td>997</td>\n",
       "      <td>376</td>\n",
       "      <td>2565</td>\n",
       "      <td>1565</td>\n",
       "      <td>718</td>\n",
       "      <td>710</td>\n",
       "      <td>2695</td>\n",
       "      <td>904</td>\n",
       "      <td>3643</td>\n",
       "      <td>655</td>\n",
       "      <td>3666</td>\n",
       "      <td>3069</td>\n",
       "      <td>3661</td>\n",
       "      <td>953</td>\n",
       "      <td>865</td>\n",
       "      <td>813</td>\n",
       "      <td>1353</td>\n",
       "      <td>2945</td>\n",
       "      <td>2580</td>\n",
       "      <td>2989</td>\n",
       "      <td>2790</td>\n",
       "      <td>2879</td>\n",
       "      <td>2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,208)</td>\n",
       "      <td>3023</td>\n",
       "      <td>1489</td>\n",
       "      <td>1916</td>\n",
       "      <td>1706</td>\n",
       "      <td>1221</td>\n",
       "      <td>1191</td>\n",
       "      <td>2671</td>\n",
       "      <td>81</td>\n",
       "      <td>2483</td>\n",
       "      <td>941</td>\n",
       "      <td>841</td>\n",
       "      <td>1617</td>\n",
       "      <td>1437</td>\n",
       "      <td>2700</td>\n",
       "      <td>1904</td>\n",
       "      <td>1763</td>\n",
       "      <td>1181</td>\n",
       "      <td>599</td>\n",
       "      <td>2442</td>\n",
       "      <td>1656</td>\n",
       "      <td>1370</td>\n",
       "      <td>1171</td>\n",
       "      <td>1372</td>\n",
       "      <td>1444</td>\n",
       "      <td>1596</td>\n",
       "      <td>2023</td>\n",
       "      <td>1456</td>\n",
       "      <td>2179</td>\n",
       "      <td>530</td>\n",
       "      <td>1949</td>\n",
       "      <td>2628</td>\n",
       "      <td>290</td>\n",
       "      <td>1996</td>\n",
       "      <td>2593</td>\n",
       "      <td>2489</td>\n",
       "      <td>3484</td>\n",
       "      <td>1035</td>\n",
       "      <td>2826</td>\n",
       "      <td>1274</td>\n",
       "      <td>595</td>\n",
       "      <td>1151</td>\n",
       "      <td>634</td>\n",
       "      <td>435</td>\n",
       "      <td>2738</td>\n",
       "      <td>3013</td>\n",
       "      <td>2605</td>\n",
       "      <td>3401</td>\n",
       "      <td>3595</td>\n",
       "      <td>2450</td>\n",
       "      <td>2052</td>\n",
       "      <td>15</td>\n",
       "      <td>501</td>\n",
       "      <td>1958</td>\n",
       "      <td>988</td>\n",
       "      <td>1920</td>\n",
       "      <td>1798</td>\n",
       "      <td>604</td>\n",
       "      <td>2793</td>\n",
       "      <td>2063</td>\n",
       "      <td>3655</td>\n",
       "      <td>3073</td>\n",
       "      <td>557</td>\n",
       "      <td>2007</td>\n",
       "      <td>1937</td>\n",
       "      <td>2244</td>\n",
       "      <td>55</td>\n",
       "      <td>1016</td>\n",
       "      <td>2382</td>\n",
       "      <td>2506</td>\n",
       "      <td>3501</td>\n",
       "      <td>914</td>\n",
       "      <td>3127</td>\n",
       "      <td>23</td>\n",
       "      <td>3187</td>\n",
       "      <td>799</td>\n",
       "      <td>2572</td>\n",
       "      <td>1038</td>\n",
       "      <td>3028</td>\n",
       "      <td>2619</td>\n",
       "      <td>1429</td>\n",
       "      <td>2623</td>\n",
       "      <td>2158</td>\n",
       "      <td>2785</td>\n",
       "      <td>3674</td>\n",
       "      <td>2578</td>\n",
       "      <td>1837</td>\n",
       "      <td>1689</td>\n",
       "      <td>296</td>\n",
       "      <td>959</td>\n",
       "      <td>3347</td>\n",
       "      <td>1707</td>\n",
       "      <td>2901</td>\n",
       "      <td>2767</td>\n",
       "      <td>2167</td>\n",
       "      <td>1921</td>\n",
       "      <td>247</td>\n",
       "      <td>1618</td>\n",
       "      <td>2016</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4,222)</td>\n",
       "      <td>1794</td>\n",
       "      <td>3535</td>\n",
       "      <td>108</td>\n",
       "      <td>593</td>\n",
       "      <td>466</td>\n",
       "      <td>2048</td>\n",
       "      <td>854</td>\n",
       "      <td>1378</td>\n",
       "      <td>1301</td>\n",
       "      <td>697</td>\n",
       "      <td>1376</td>\n",
       "      <td>22</td>\n",
       "      <td>2135</td>\n",
       "      <td>3657</td>\n",
       "      <td>3173</td>\n",
       "      <td>1322</td>\n",
       "      <td>976</td>\n",
       "      <td>6</td>\n",
       "      <td>1399</td>\n",
       "      <td>817</td>\n",
       "      <td>2757</td>\n",
       "      <td>2010</td>\n",
       "      <td>652</td>\n",
       "      <td>458</td>\n",
       "      <td>1227</td>\n",
       "      <td>204</td>\n",
       "      <td>592</td>\n",
       "      <td>2875</td>\n",
       "      <td>1930</td>\n",
       "      <td>2251</td>\n",
       "      <td>1654</td>\n",
       "      <td>2542</td>\n",
       "      <td>1149</td>\n",
       "      <td>3089</td>\n",
       "      <td>454</td>\n",
       "      <td>2466</td>\n",
       "      <td>3461</td>\n",
       "      <td>1770</td>\n",
       "      <td>3106</td>\n",
       "      <td>2275</td>\n",
       "      <td>1100</td>\n",
       "      <td>906</td>\n",
       "      <td>1814</td>\n",
       "      <td>421</td>\n",
       "      <td>2418</td>\n",
       "      <td>866</td>\n",
       "      <td>3607</td>\n",
       "      <td>821</td>\n",
       "      <td>213</td>\n",
       "      <td>432</td>\n",
       "      <td>34</td>\n",
       "      <td>2578</td>\n",
       "      <td>2517</td>\n",
       "      <td>2221</td>\n",
       "      <td>2818</td>\n",
       "      <td>2420</td>\n",
       "      <td>2738</td>\n",
       "      <td>2141</td>\n",
       "      <td>3013</td>\n",
       "      <td>3610</td>\n",
       "      <td>959</td>\n",
       "      <td>1927</td>\n",
       "      <td>2524</td>\n",
       "      <td>932</td>\n",
       "      <td>3327</td>\n",
       "      <td>187</td>\n",
       "      <td>2575</td>\n",
       "      <td>1674</td>\n",
       "      <td>557</td>\n",
       "      <td>2547</td>\n",
       "      <td>1572</td>\n",
       "      <td>776</td>\n",
       "      <td>1600</td>\n",
       "      <td>2682</td>\n",
       "      <td>2085</td>\n",
       "      <td>1987</td>\n",
       "      <td>1390</td>\n",
       "      <td>614</td>\n",
       "      <td>3098</td>\n",
       "      <td>1831</td>\n",
       "      <td>927</td>\n",
       "      <td>2285</td>\n",
       "      <td>1059</td>\n",
       "      <td>2850</td>\n",
       "      <td>3517</td>\n",
       "      <td>134</td>\n",
       "      <td>1852</td>\n",
       "      <td>2776</td>\n",
       "      <td>1694</td>\n",
       "      <td>2490</td>\n",
       "      <td>1332</td>\n",
       "      <td>2526</td>\n",
       "      <td>2804</td>\n",
       "      <td>2027</td>\n",
       "      <td>833</td>\n",
       "      <td>176</td>\n",
       "      <td>463</td>\n",
       "      <td>2851</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  (user_id, item_id)  id-1  id-2  id-3  id-4  id-5  id-6  id-7  id-8  id-9  \\\n",
       "0             (0,25)  1064   174  2791  3373   269  2678  1902  3641  1216   \n",
       "1            (1,133)  1072  3154  3368  3644   549  1810   937  1514  1713   \n",
       "2            (2,207)  2216   209  2347     3  1652  3397   383  2905  2284   \n",
       "3            (3,208)  3023  1489  1916  1706  1221  1191  2671    81  2483   \n",
       "4            (4,222)  1794  3535   108   593   466  2048   854  1378  1301   \n",
       "\n",
       "   id-10  id-11  id-12  id-13  id-14  id-15  id-16  id-17  id-18  id-19  \\\n",
       "0    915   3672   2803   2344    986   3217   2824   2598    464   2340   \n",
       "1   2186    660   2303   2416    670   1176    788    889   3120   2344   \n",
       "2   2866    584    783   3208   1534   2529   1907   1170   3037   2015   \n",
       "3    941    841   1617   1437   2700   1904   1763   1181    599   2442   \n",
       "4    697   1376     22   2135   3657   3173   1322    976      6   1399   \n",
       "\n",
       "   id-20  id-21  id-22  id-23  id-24  id-25  id-26  id-27  id-28  id-29  \\\n",
       "0   1952   1855   1353   1547   3487   3293   1541   2414   2728    340   \n",
       "1   2525   3301   2055   1436   2630     11   2773   2176   1847    740   \n",
       "2   1045   3099   3298   2522    739   2652   3702    792   2527   1945   \n",
       "3   1656   1370   1171   1372   1444   1596   2023   1456   2179    530   \n",
       "4    817   2757   2010    652    458   1227    204    592   2875   1930   \n",
       "\n",
       "   id-30  id-31  id-32  id-33  id-34  id-35  id-36  id-37  id-38  id-39  \\\n",
       "0   1421   1963   2545    972    487   3463   2727   1135   3135    128   \n",
       "1   2332   3561    263   3658   3282   1980   2093   3287   3190   3475   \n",
       "2   2333   1668   3511     70   1991   3071   2474   1629   3221    505   \n",
       "3   1949   2628    290   1996   2593   2489   3484   1035   2826   1274   \n",
       "4   2251   1654   2542   1149   3089    454   2466   3461   1770   3106   \n",
       "\n",
       "   id-40  id-41  id-42  id-43  id-44  id-45  id-46  id-47  id-48  id-49  \\\n",
       "0    175   2423   1974   2515   3278   3079   1527   2182   1018   2800   \n",
       "1    569   2315   1442    592    546   3133   1852   2648    934    337   \n",
       "2   3266   1475    515   2704   1717    569   3248    241   2643   2137   \n",
       "3    595   1151    634    435   2738   3013   2605   3401   3595   2450   \n",
       "4   2275   1100    906   1814    421   2418    866   3607    821    213   \n",
       "\n",
       "   id-50  id-51  id-52  id-53  id-54  id-55  id-56  id-57  id-58  id-59  \\\n",
       "0   1830   1539    617    247   3448   1699   1420   2487    198    811   \n",
       "1    483   1017   3452    467   1183   1765    601   2413   2602   2801   \n",
       "2   2336   2627   2618   2748   2967   2579   1732   3283   1440   1052   \n",
       "3   2052     15    501   1958    988   1920   1798    604   2793   2063   \n",
       "4    432     34   2578   2517   2221   2818   2420   2738   2141   3013   \n",
       "\n",
       "   id-60  id-61  id-62  id-63  id-64  id-65  id-66  id-67  id-68  id-69  \\\n",
       "0   1010   1423   2840   1770    881   1913   1803   1734   3326   1617   \n",
       "1   2976    918    753   3540   3341   2973   1580   2118   3511    526   \n",
       "2   1906   1812   1182   2831   1548   1630   2227   2352    760    350   \n",
       "3   3655   3073    557   2007   1937   2244     55   1016   2382   2506   \n",
       "4   3610    959   1927   2524    932   3327    187   2575   1674    557   \n",
       "\n",
       "   id-70  id-71  id-72  id-73  id-74  id-75  id-76  id-77  id-78  id-79  \\\n",
       "0    224   3352   1869   1182   1331    336   2517   1721   3512   3656   \n",
       "1   1719    525   1520    486    557   1353    500   2902   1687   1295   \n",
       "2    302    791    300   3528   1444      2    798    997    376   2565   \n",
       "3   3501    914   3127     23   3187    799   2572   1038   3028   2619   \n",
       "4   2547   1572    776   1600   2682   2085   1987   1390    614   3098   \n",
       "\n",
       "   id-80  id-81  id-82  id-83  id-84  id-85  id-86  id-87  id-88  id-89  \\\n",
       "0    273   1026   1991   2190    998   3386   3369    185   2822    864   \n",
       "1   2997   2415    797   2518    926   3537   1746   1676   1875   3029   \n",
       "2   1565    718    710   2695    904   3643    655   3666   3069   3661   \n",
       "3   1429   2623   2158   2785   3674   2578   1837   1689    296    959   \n",
       "4   1831    927   2285   1059   2850   3517    134   1852   2776   1694   \n",
       "\n",
       "   id-90  id-91  id-92  id-93  id-94  id-95  id-96  id-97  id-98  id-99  \n",
       "0   2854   3067     58   2551   2333   2688   3703   1300   1924   3118  \n",
       "1   1535    341   3525   1429   2225   1628   2061    469   3056   2553  \n",
       "2    953    865    813   1353   2945   2580   2989   2790   2879   2481  \n",
       "3   3347   1707   2901   2767   2167   1921    247   1618   2016   2323  \n",
       "4   2490   1332   2526   2804   2027    833    176    463   2851   2453  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfUQa6wDf_21",
    "outputId": "f470834c-b8c3-47b2-d2bc-f4ea34f56d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMF Init: MRR = 0.0267, NDCG = 0.0424\t t1 = [2.6013110717137655s]\n",
      "MLP Init: MRR = 0.0289, NDCG = 0.0449\t t1 = [2.523220431804657s]\n",
      "NMF Init: MRR = 0.0285, NDCG = 0.0436\t t1 = [2.5350362340609234s]\n"
     ]
    }
   ],
   "source": [
    "models = [('GMF', gmf_model), ('MLP', mlp_model), ('NMF', nmf_model)]\n",
    "def initPerformance():\n",
    "  # Init performance\n",
    "  for name, model in models:\n",
    "    t1 = time()\n",
    "    mrr, ndcg = evaluate_model(model, test_rating, test_negative, TOP_K)\n",
    "    print(f'{name} Init: MRR = {mrr:.4f}, NDCG = {ndcg:.4f}\\t t1 = [{(time()-t1)/60}s]')\n",
    "initPerformance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. How the values of MRR and NDCG are differ from the results you got in the previous exercises which implemented the explicit recommendation approach. \n",
    "What are the difference in preparing the dataset for evaluation.\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. How will you measure item similarity using the NeuMF model?\n",
    "\n",
    "##### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 3: Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. One of the enhancements presented in the Neural Collaborative Filtering paper is the usage of probabilistic activation function (the sigmoid) and binary cross entropy loss function.   \n",
    "\n",
    "Select one of the models you implemented in question 2 and change the loss function to a Mean Squared Error and the activation function of the last layer to RELU.   \n",
    "\n",
    "Train the model and evaluate it in a similar way to what you did in question 2. \n",
    "Compare the results and discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 8)         48320       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 8)         29648       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 8)            0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 8)            0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16)           0           flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 32)           544         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 16)           528         layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 8)            136         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            9           layer2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 79,185\n",
      "Trainable params: 79,185\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3a = get_MLP_model(num_users, num_items, num_factors, regs = [[0,0],0,0,0], layers = [32,16,8], activation='relu')\n",
    "model_3a.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "model_3a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
