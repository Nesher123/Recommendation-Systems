{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralCollaborativeFiltering_Implicit",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt0kJ_5RnP32"
      },
      "source": [
        "## **Neural Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE5xAcHYmmmx"
      },
      "source": [
        "This notebook is based on the implementation by the author of the \"Neural Collaborative Filtering\" paper. [Link](https://github.com/hexiangnan/neural_collaborative_filtering\r\n",
        ") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm-4UC9-nGM4"
      },
      "source": [
        "Neural Collaborative Filtering\r\n",
        "This is our implementation for the paper:\r\n",
        "\r\n",
        "Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu and Tat-Seng Chua (2017). Neural Collaborative Filtering. In Proceedings of WWW '17, Perth, Australia, April 03-07, 2017.\r\n",
        "\r\n",
        "Three collaborative filtering models: Generalized Matrix Factorization (GMF), Multi-Layer Perceptron (MLP), and Neural Matrix Factorization (NeuMF). To target the models for implicit feedback and ranking task, we optimize them using log loss with negative sampling.\r\n",
        "\r\n",
        "Please cite our WWW'17 paper if you use our codes. Thanks!\r\n",
        "\r\n",
        "Author: Dr. Xiangnan He (http://www.comp.nus.edu.sg/~xiangnan/)[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZADvPXH5wfD"
      },
      "source": [
        "'''\r\n",
        "Created on Aug 9, 2016\r\n",
        "Updated on May 20, 2018\r\n",
        "\r\n",
        "Keras Implementation of Generalized Matrix Factorization (GMF) recommender model in:\r\n",
        "He Xiangnan et al. Neural Collaborative Filtering. In WWW 2017.  \r\n",
        "\r\n",
        "@original author: Xiangnan He (xiangnanhe@gmail.com)\r\n",
        "@Updated and placed on notebooks: Guy Shtar (shtar@post.bgu.ac.il)\r\n",
        "'''\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as T\r\n",
        "from tensorflow import keras\r\n",
        "from keras import backend as K\r\n",
        "from keras import initializers\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from keras.models import Sequential, Model, load_model, save_model\r\n",
        "from keras.layers.core import Dense, Lambda, Activation\r\n",
        "from keras.layers import Embedding, Input, Dense, Reshape,  Flatten, Dropout\r\n",
        "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.layers import Multiply, Concatenate\r\n",
        "from time import time\r\n",
        "import multiprocessing as mp\r\n",
        "import sys\r\n",
        "import math\r\n",
        "import argparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlsbSNGcnmmH"
      },
      "source": [
        "Dataset handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjkvmzZn8B-h"
      },
      "source": [
        "import scipy.sparse as sp\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class Dataset(object):\r\n",
        "    '''\r\n",
        "    classdocs\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self, path):\r\n",
        "        '''\r\n",
        "        Constructor\r\n",
        "        '''\r\n",
        "        self.trainMatrix = self.load_rating_file_as_matrix(path + \".train.rating\")\r\n",
        "        self.testRatings = self.load_rating_file_as_list(path + \".test.rating\")\r\n",
        "        self.testNegatives = self.load_negative_file(path + \".test.negative\")\r\n",
        "        assert len(self.testRatings) == len(self.testNegatives)\r\n",
        "        \r\n",
        "        self.num_users, self.num_items = self.trainMatrix.shape\r\n",
        "        \r\n",
        "    def load_rating_file_as_list(self, filename):\r\n",
        "        ratingList = []\r\n",
        "        with open(filename, \"r\") as f:\r\n",
        "            line = f.readline()\r\n",
        "            while line != None and line != \"\":\r\n",
        "                arr = line.split(\"\\t\")\r\n",
        "                user, item = int(arr[0]), int(arr[1])\r\n",
        "                ratingList.append([user, item])\r\n",
        "                line = f.readline()\r\n",
        "        return ratingList\r\n",
        "    \r\n",
        "    def load_negative_file(self, filename):\r\n",
        "        negativeList = []\r\n",
        "        with open(filename, \"r\") as f:\r\n",
        "            line = f.readline()\r\n",
        "            while line != None and line != \"\":\r\n",
        "                arr = line.split(\"\\t\")\r\n",
        "                negatives = []\r\n",
        "                for x in arr[1: ]:\r\n",
        "                    negatives.append(int(x))\r\n",
        "                negativeList.append(negatives)\r\n",
        "                line = f.readline()\r\n",
        "        return negativeList\r\n",
        "    \r\n",
        "    def load_rating_file_as_matrix(self, filename):\r\n",
        "        '''\r\n",
        "        Read .rating file and Return dok matrix.\r\n",
        "        The first line of .rating file is: num_users\\t num_items\r\n",
        "        '''\r\n",
        "        # Get number of users and items\r\n",
        "        num_users, num_items = 0, 0\r\n",
        "        with open(filename, \"r\") as f:\r\n",
        "            line = f.readline()\r\n",
        "            while line != None and line != \"\":\r\n",
        "                arr = line.split(\"\\t\")\r\n",
        "                u, i = int(arr[0]), int(arr[1])\r\n",
        "                num_users = max(num_users, u)\r\n",
        "                num_items = max(num_items, i)\r\n",
        "                line = f.readline()\r\n",
        "        # Construct matrix\r\n",
        "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\r\n",
        "        with open(filename, \"r\") as f:\r\n",
        "            line = f.readline()\r\n",
        "            while line != None and line != \"\":\r\n",
        "                arr = line.split(\"\\t\")\r\n",
        "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\r\n",
        "                if (rating > 0):\r\n",
        "                    mat[user, item] = 1.0\r\n",
        "                line = f.readline()    \r\n",
        "        return mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phL8meRGnql2"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAzRQpw58VFv"
      },
      "source": [
        "import math\r\n",
        "import heapq # for retrieval topK\r\n",
        "import multiprocessing\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "#from numba import jit, autojit\r\n",
        "\r\n",
        "# Global variables that are shared across processes\r\n",
        "_model = None\r\n",
        "_testRatings = None\r\n",
        "_testNegatives = None\r\n",
        "_K = None\r\n",
        "\r\n",
        "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\r\n",
        "    \"\"\"\r\n",
        "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\r\n",
        "    Return: score of each test rating.\r\n",
        "    \"\"\"\r\n",
        "    global _model\r\n",
        "    global _testRatings\r\n",
        "    global _testNegatives\r\n",
        "    global _K\r\n",
        "    _model = model\r\n",
        "    _testRatings = testRatings\r\n",
        "    _testNegatives = testNegatives\r\n",
        "    _K = K\r\n",
        "        \r\n",
        "    hits, ndcgs = [],[]\r\n",
        "    if(num_thread > 1): # Multi-thread\r\n",
        "        pool = multiprocessing.Pool(processes=num_thread)\r\n",
        "        res = pool.map(eval_one_rating, range(len(_testRatings)))\r\n",
        "        pool.close()\r\n",
        "        pool.join()\r\n",
        "        hits = [r[0] for r in res]\r\n",
        "        ndcgs = [r[1] for r in res]\r\n",
        "        return (hits, ndcgs)\r\n",
        "    # Single thread\r\n",
        "    for idx in range(len(_testRatings)):\r\n",
        "        (hr,ndcg) = eval_one_rating(idx)\r\n",
        "        hits.append(hr)\r\n",
        "        ndcgs.append(ndcg)      \r\n",
        "    return (hits, ndcgs)\r\n",
        "\r\n",
        "def eval_one_rating(idx):\r\n",
        "    rating = _testRatings[idx]\r\n",
        "    items = _testNegatives[idx]\r\n",
        "    u = rating[0]\r\n",
        "    gtItem = rating[1]\r\n",
        "    items.append(gtItem)\r\n",
        "    # Get prediction scores\r\n",
        "    map_item_score = {}\r\n",
        "    users = np.full(len(items), u, dtype = 'int32')\r\n",
        "    predictions = _model.predict([users, np.array(items)], \r\n",
        "                                 batch_size=100, verbose=0)\r\n",
        "    for i in range(len(items)):\r\n",
        "        item = items[i]\r\n",
        "        map_item_score[item] = predictions[i]\r\n",
        "    items.pop()\r\n",
        "    \r\n",
        "    # Evaluate top rank list\r\n",
        "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\r\n",
        "    hr = getHitRatio(ranklist, gtItem)\r\n",
        "    ndcg = getNDCG(ranklist, gtItem)\r\n",
        "    return (hr, ndcg)\r\n",
        "\r\n",
        "def getHitRatio(ranklist, gtItem):\r\n",
        "    for item in ranklist:\r\n",
        "        if item == gtItem:\r\n",
        "            return 1\r\n",
        "    return 0\r\n",
        "\r\n",
        "def getNDCG(ranklist, gtItem):\r\n",
        "    for i in range(len(ranklist)):\r\n",
        "        item = ranklist[i]\r\n",
        "        if item == gtItem:\r\n",
        "            return math.log(2) / math.log(i+2)\r\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z98tuYWLAcWE",
        "outputId": "496b5c78-9298-4912-dd62-9273e21e25a8"
      },
      "source": [
        "!ls drive/MyDrive/RS/Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item_price.csv\t   ml-1m.test.negative\tml-1m.train.rating\n",
            "item_priceold.csv  ml-1m.test.rating\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV1al-v0zWt1"
      },
      "source": [
        "You can download the dataset from the author's github or from my drive:\r\n",
        "\r\n",
        "[ml-1m.test.negative](https://https://drive.google.com/file/d/1v3XEN7pjtsjzxx5fuioNbIzMOyom1nNn/view?usp=sharing)\r\n",
        "\r\n",
        "[ml-1m.test.rating](https://drive.google.com/file/d/1TldYS-vtNVAFPXvDTYuuhi3cky37yXK0/view?usp=sharing)\r\n",
        "\r\n",
        "[ml-1m.train.rating](https://https://drive.google.com/file/d/1rFxJ8rG9LVczeCmKC7AXo2Y6sFXo7maG/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdBDv872_8lT",
        "outputId": "ece9ffcf-4515-43ba-e3f7-3a8c0f0e1d1b"
      },
      "source": [
        "# Loading data\r\n",
        "path='drive/MyDrive/RS/Data/'\r\n",
        "dataset='ml-1m'\r\n",
        "#dataset='pinterest-20'\r\n",
        "t1 = time()\r\n",
        "dataset = Dataset(path + dataset)\r\n",
        "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\r\n",
        "num_users, num_items = train.shape\r\n",
        "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\" \r\n",
        "      %(time()-t1, num_users, num_items, train.nnz, len(testRatings)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load data done [20.5 s]. #user=6040, #item=3706, #train=994169, #test=6040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LrGCcWY_KHj",
        "outputId": "62703202-3fd2-4d0c-8490-6ef0d2eb702b"
      },
      "source": [
        "num_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekg1Cn8BBGjZ",
        "outputId": "8bd60362-4c43-449e-a078-5270b3f3fa32"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.dok.dok_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw5OuOkZqhxF"
      },
      "source": [
        "Add Negative Sampling to Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7nlDtDaCakQ"
      },
      "source": [
        "def get_train_instances(train, num_negatives):\r\n",
        "    user_input, item_input, labels = [],[],[]\r\n",
        "    num_users = train.shape[0]\r\n",
        "    for (u, i) in train.keys():\r\n",
        "        # positive instance\r\n",
        "        user_input.append(u)\r\n",
        "        item_input.append(i)\r\n",
        "        labels.append(1)\r\n",
        "        # negative instances\r\n",
        "        for t in range(num_negatives):\r\n",
        "            j = np.random.randint(num_items)\r\n",
        "            while (u, j) in train:\r\n",
        "                j = np.random.randint(num_items)\r\n",
        "            user_input.append(u)\r\n",
        "            item_input.append(j)\r\n",
        "            labels.append(0)\r\n",
        "    return user_input, item_input, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mbakwY5qs0s"
      },
      "source": [
        "Define three models: GMF, MLP and NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdtoQge9CnXI"
      },
      "source": [
        "def get_GMF_model(num_users, num_items, latent_dim, regs=[[0,0]]):\r\n",
        "    #Generalized Matrix Factorization\r\n",
        "    \r\n",
        "    # Input variables\r\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
        "\r\n",
        "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \r\n",
        "    \r\n",
        "    # Crucial to flatten an embedding vector!\r\n",
        "    user_latent = Flatten()(MF_Embedding_User(user_input))\r\n",
        "    item_latent = Flatten()(MF_Embedding_Item(item_input))\r\n",
        "    \r\n",
        "    # Element-wise product of user and item embeddings \r\n",
        "    predict_vector = Multiply()([user_latent, item_latent]) #merge([user_latent, item_latent], mode = 'mul')\r\n",
        "    \r\n",
        "    # Final prediction layer\r\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(predict_vector)\r\n",
        "    \r\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def get_MLP_model(num_users, num_items, latent_dim, regs=[[0,0],0,0], layers = [20,10]):\r\n",
        "    #Multi-Layer Perceptron\r\n",
        "    \r\n",
        "    assert len(layers) + 1 == len(regs), 'the number of regs is equal to number of layers + the embedding layer'\r\n",
        "    num_layer = len(layers) #Number of layers in the MLP\r\n",
        "    # Input variables\r\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
        "\r\n",
        "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    \r\n",
        "    # Crucial to flatten an embedding vector!\r\n",
        "    user_latent = Flatten()(MLP_Embedding_User(user_input))\r\n",
        "    item_latent = Flatten()(MLP_Embedding_Item(item_input))\r\n",
        "    \r\n",
        "    # Concatenation of embedding layers\r\n",
        "    vector = Concatenate(axis=-1)([user_latent, item_latent])#merge([user_latent, item_latent], mode = 'concat')\r\n",
        "    \r\n",
        "    # MLP layers\r\n",
        "    for idx in range(num_layer):\r\n",
        "        layer = Dense(layers[idx], kernel_regularizer = l2(regs[idx+1]), activation='relu', name = 'layer%d' %idx)\r\n",
        "        vector = layer(vector)\r\n",
        "        \r\n",
        "    # Final prediction layer\r\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(vector)\r\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
        "    return model\r\n",
        "\r\n",
        "def get_NMF_model(num_users, num_items, latent_dim_GMF, latent_dim_MLP, reg_GMF=[[0,0]], regs_MLP=[[0,0],0,0], layers=[20,10]):\r\n",
        "    #Neural matrix factorization\r\n",
        "    assert len(layers) + 1 == len(regs_MLP), 'the number of regs is equal to number of layers + the embedding layer'\r\n",
        "    num_layer = len(layers) #Number of layers in the MLP\r\n",
        "\r\n",
        "    # Input variables\r\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
        "    \r\n",
        "    # Embedding layer\r\n",
        "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_GMF, name = 'MF_user_embedding',\r\n",
        "                                   embeddings_regularizer = l2(reg_GMF[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_GMF, name = 'MF_item_embedding',\r\n",
        "                                   embeddings_regularizer = l2(reg_GMF[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \r\n",
        "    \r\n",
        "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_MLP, name = 'MLP_user_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs_MLP[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_MLP, name = 'MLP_item_embedding',\r\n",
        "                                   embeddings_regularizer = l2(regs_MLP[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
        "    \r\n",
        "    # MF part\r\n",
        "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\r\n",
        "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\r\n",
        "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) #merge([mf_user_latent, mf_item_latent], mode = 'mul') # element-wise multiply\r\n",
        "\r\n",
        "    # MLP part \r\n",
        "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\r\n",
        "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\r\n",
        "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])#merge([mlp_user_latent, mlp_item_latent], mode = 'concat')\r\n",
        "    for idx in range(num_layer):\r\n",
        "        layer =  Dense(layers[idx], kernel_regularizer = l2(regs_MLP[idx+1]), activation='tanh', name = 'layer%d' %idx)\r\n",
        "        mlp_vector = layer(mlp_vector)\r\n",
        "\r\n",
        "    # Concatenate MF and MLP parts\r\n",
        "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\r\n",
        "    \r\n",
        "    # Final prediction layer\r\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)    \r\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0q2uQaAf16m",
        "outputId": "19a241cd-d0fc-41e7-933e-c4dae5011e76"
      },
      "source": [
        "num_factors = 8 #size of embedding size. Can be split to 4 different params potentially.\r\n",
        "num_negatives = 4 #how many negative samples per positive sample?\r\n",
        "learning_rate = 0.001\r\n",
        "epochs = 10\r\n",
        "batch_size = 256\r\n",
        "verbose = 1\r\n",
        "write_model=False\r\n",
        "topK = 10 #used to evaluate the model. Top K recommendations are used.\r\n",
        "evaluation_threads = 1 \r\n",
        "model_out_file = 'Pretrain/%s_GMF_%d_%d.h5' %(dataset, num_factors, time())\r\n",
        "\r\n",
        "# Build model\r\n",
        "#model = get_GMF_model(num_users, num_items, num_factors, regs = [[0,0]])\r\n",
        "#model = get_MLP_model(num_users, num_items, num_factors, regs = [[0,0],0,0,0], layers = [32,16,8])\r\n",
        "model = get_NMF_model(num_users, num_items, latent_dim_GMF=num_factors, latent_dim_MLP=num_factors, reg_GMF=[[0,0]],\r\n",
        "                      regs_MLP=[[0,0],0,0,0], layers=[32,16,8])\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "MLP_user_embedding (Embedding)  (None, 1, 8)         48320       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "MLP_item_embedding (Embedding)  (None, 1, 8)         29648       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8)            0           MLP_user_embedding[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 8)            0           MLP_item_embedding[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16)           0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "MF_user_embedding (Embedding)   (None, 1, 8)         48320       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "MF_item_embedding (Embedding)   (None, 1, 8)         29648       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer0 (Dense)                  (None, 32)           544         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8)            0           MF_user_embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8)            0           MF_item_embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "layer1 (Dense)                  (None, 16)           528         layer0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 8)            0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer2 (Dense)                  (None, 8)            136         layer1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16)           0           multiply[0][0]                   \n",
            "                                                                 layer2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            17          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 157,161\n",
            "Trainable params: 157,161\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We10CDQurED6"
      },
      "source": [
        "Random Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfUQa6wDf_21",
        "outputId": "f470834c-b8c3-47b2-d2bc-f4ea34f56d0e"
      },
      "source": [
        "# Init performance\r\n",
        "t1 = time()\r\n",
        "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\r\n",
        "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\r\n",
        "print('Init: HR = %.4f, NDCG = %.4f\\t [%.1f s]' % (hr, ndcg, time()-t1))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init: HR = 0.0892, NDCG = 0.0402\t [238.8 s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPeeX-j-S7_"
      },
      "source": [
        "import numpy as np\r\n",
        "item_price = {}\r\n",
        "for (u,i) in train.keys():  \r\n",
        "  if i not in item_price:\r\n",
        "      item_price[i] = np.random.choice([1,2,4,9,25],p=[0.35,0.25,0.2,0.15,0.05])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8lm6BU_YvB",
        "outputId": "6c4262b4-0f0e-4536-cdc9-80313be1d6cb"
      },
      "source": [
        "len(item_price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiQIXlPxBIx0"
      },
      "source": [
        "item_price_sorted = {k: v for k, v in sorted(item_price.items(), key=lambda item: item[0])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gvshsj5QChBx",
        "outputId": "a283540c-3be7-47ae-e17f-55927082c7cd"
      },
      "source": [
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/MyDrive/RS/Data/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx3bIigKBT0N"
      },
      "source": [
        "import csv\r\n",
        "with open(path+'item_price_test.csv', 'w') as f:\r\n",
        "    f.write('item,price'+'\\n')\r\n",
        "    for key in item_price_sorted.keys():\r\n",
        "        f.write(\"%s,%s\\n\"%(key,item_price_sorted[key]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frJfo7uCA3k4"
      },
      "source": [
        "import numpy as np\r\n",
        "item_price = {}\r\n",
        "with open(path+'item_price.csv', 'w') as f:\r\n",
        "  for i in range(num_items):  \r\n",
        "      item_price[i] = np.random.choice([1,2,4,9,25],p=[0.35,0.25,0.2,0.15,0.05])\r\n",
        "      f.write(\"%s,%s\\n\"%(i,item_price[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhpmhtRPCFAm",
        "outputId": "a62654f5-382b-4f63-8b51-b072e76f0a81"
      },
      "source": [
        "len(item_price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QmMHuJ_Cve4",
        "outputId": "534f5f48-58ec-458d-c6ef-bd2ae0a14c76"
      },
      "source": [
        "# Train model\r\n",
        "best_hr, best_ndcg, best_iter = hr, ndcg, -1\r\n",
        "for epoch in range(epochs):\r\n",
        "    t1 = time()\r\n",
        "    # Generate training instances\r\n",
        "    user_input, item_input, labels = get_train_instances(train, num_negatives)\r\n",
        "\r\n",
        "    # Training\r\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\r\n",
        "                     np.array(labels), # labels \r\n",
        "                     batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\r\n",
        "    t2 = time()\r\n",
        "\r\n",
        "    # Evaluation\r\n",
        "    if epoch %verbose == 0:\r\n",
        "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\r\n",
        "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\r\n",
        "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' \r\n",
        "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\r\n",
        "        if hr > best_hr:\r\n",
        "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\r\n",
        "            if write_model:\r\n",
        "                model.save_weights(model_out_file, overwrite=True)\r\n",
        "\r\n",
        "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\r\n",
        "if write_model:\r\n",
        "    print(\"The best GMF model is saved to %s\" %(model_out_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 [54.4 s]: HR = 0.5955, NDCG = 0.3354, loss = 0.3196 [226.4 s]\n",
            "Iteration 1 [54.7 s]: HR = 0.6316, NDCG = 0.3651, loss = 0.2771 [228.6 s]\n",
            "Iteration 2 [55.1 s]: HR = 0.6435, NDCG = 0.3755, loss = 0.2683 [226.7 s]\n",
            "Iteration 3 [53.9 s]: HR = 0.6575, NDCG = 0.3832, loss = 0.2641 [227.7 s]\n",
            "Iteration 4 [53.2 s]: HR = 0.6573, NDCG = 0.3845, loss = 0.2614 [226.3 s]\n",
            "Iteration 5 [53.3 s]: HR = 0.6608, NDCG = 0.3875, loss = 0.2592 [227.8 s]\n",
            "Iteration 6 [53.8 s]: HR = 0.6636, NDCG = 0.3917, loss = 0.2575 [227.2 s]\n",
            "Iteration 7 [52.9 s]: HR = 0.6659, NDCG = 0.3908, loss = 0.2559 [230.8 s]\n",
            "Iteration 8 [53.1 s]: HR = 0.6677, NDCG = 0.3920, loss = 0.2546 [227.9 s]\n",
            "Iteration 9 [53.3 s]: HR = 0.6684, NDCG = 0.3918, loss = 0.2536 [226.0 s]\n",
            "End. Best Iteration 9:  HR = 0.6684, NDCG = 0.3918. \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}