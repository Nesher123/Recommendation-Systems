{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_uPLYR1msZk"
   },
   "source": [
    "#**Amir Golan (204327050), Nadav Loebl (203766985)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C-adz_yn3TP"
   },
   "source": [
    "Cloning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqCr4jpHmk4j",
    "outputId": "a703245d-fd76-40cf-c9ee-8ec387bbefe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'neural_collaborative_filtering'...\n",
      "remote: Enumerating objects: 66, done.\u001b[K\n",
      "remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 66\u001b[K\n",
      "Unpacking objects: 100% (66/66), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hexiangnan/neural_collaborative_filtering.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hyoy2Ann2TA",
    "outputId": "84d98e52-613d-4d90-ca8c-faf113aeae7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls neural_collaborative_filtering/Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLL8TZqZo7c5"
   },
   "source": [
    "Reading the csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rH13Uzjdn51N"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\r\n",
    "training = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.train.rating', '\\t', names=names)\r\n",
    "test_rating = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.rating', '\\t', names=names)\r\n",
    "negative_ids = []\r\n",
    "negative_ids.append(f'(user_id, item_id)')\r\n",
    "for i in range(1,100):\r\n",
    "  negative_ids.append(f'id-{i}')\r\n",
    "test_negative = pd.read_csv('./neural_collaborative_filtering/Data/ml-1m.test.negative', '\\t', names=negative_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtbeaa5Q1Ap1"
   },
   "source": [
    "#1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "lfBhZV2_odfd",
    "outputId": "30328b59-80f5-4e0a-cb39-4b0e5a51e480"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       32       4  978824330\n",
       "1        0       34       4  978824330\n",
       "2        0        4       5  978824291\n",
       "3        0       35       4  978824291\n",
       "4        0       30       4  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "v4kTK62JohKO",
    "outputId": "1f4d55bb-ce00-4a13-a533-2048b11369ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>994169.000000</td>\n",
       "      <td>994169.000000</td>\n",
       "      <td>994169.000000</td>\n",
       "      <td>9.941690e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3023.536725</td>\n",
       "      <td>872.860828</td>\n",
       "      <td>3.581378</td>\n",
       "      <td>9.722116e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1728.320003</td>\n",
       "      <td>738.213243</td>\n",
       "      <td>1.116791</td>\n",
       "      <td>1.208143e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.567039e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1505.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.653021e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3071.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.729723e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4475.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.752182e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6039.000000</td>\n",
       "      <td>3705.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.046455e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        item_id         rating     timestamp\n",
       "count  994169.000000  994169.000000  994169.000000  9.941690e+05\n",
       "mean     3023.536725     872.860828       3.581378  9.722116e+08\n",
       "std      1728.320003     738.213243       1.116791  1.208143e+07\n",
       "min         0.000000       0.000000       1.000000  9.567039e+08\n",
       "25%      1505.000000     258.000000       3.000000  9.653021e+08\n",
       "50%      3071.000000     690.000000       4.000000  9.729723e+08\n",
       "75%      4475.000000    1283.000000       4.000000  9.752182e+08\n",
       "max      6039.000000    3705.000000       5.000000  1.046455e+09"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm1sm_zvpdko"
   },
   "source": [
    "So, ml-1m.train.rating is the training file. Each line is a training instance tab (\\t) sepeated of: userID, itemID, rating, timestamp (if have). This file is similar to the original ml-1m training files, the difference is that it contains only users with at least 20 ratings (to avoid situation where a user has only one rating). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "RyNUUIClo052",
    "outputId": "c59c30c2-6526-4f9c-ab65-4e1adbb6fc62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       25       5  978824351\n",
       "1        1      133       3  978300174\n",
       "2        2      207       4  978298504\n",
       "3        3      208       4  978294282\n",
       "4        4      222       2  978246585"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "0odXGbxfpGyI",
    "outputId": "51835e88-fa60-408d-b28a-0dd262eac290"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6.040000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3019.500000</td>\n",
       "      <td>939.856623</td>\n",
       "      <td>3.612252</td>\n",
       "      <td>9.775217e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1743.742145</td>\n",
       "      <td>789.260796</td>\n",
       "      <td>1.166819</td>\n",
       "      <td>2.008596e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.567124e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1509.750000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.654912e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3019.500000</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.745024e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4529.250000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.764266e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6039.000000</td>\n",
       "      <td>3573.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.046455e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id      item_id       rating     timestamp\n",
       "count  6040.000000  6040.000000  6040.000000  6.040000e+03\n",
       "mean   3019.500000   939.856623     3.612252  9.775217e+08\n",
       "std    1743.742145   789.260796     1.166819  2.008596e+07\n",
       "min       0.000000     0.000000     1.000000  9.567124e+08\n",
       "25%    1509.750000   277.000000     3.000000  9.654912e+08\n",
       "50%    3019.500000   741.000000     4.000000  9.745024e+08\n",
       "75%    4529.250000  1400.000000     5.000000  9.764266e+08\n",
       "max    6039.000000  3573.000000     5.000000  1.046455e+09"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1R41X7stvuS"
   },
   "source": [
    "Now,  ml-1m.test.rating is the (rating) test file for positives instances. Each line is a testing instance tab (\\t) sepeated of: userID, itemID, rating, timestamp (if have). The difference is that here we have only one rating for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "wWccJYbnpIXY",
    "outputId": "01f2411c-f7b9-4c83-d13a-9e0d8ff67e74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(user_id, item_id)</th>\n",
       "      <th>id-1</th>\n",
       "      <th>id-2</th>\n",
       "      <th>id-3</th>\n",
       "      <th>id-4</th>\n",
       "      <th>id-5</th>\n",
       "      <th>id-6</th>\n",
       "      <th>id-7</th>\n",
       "      <th>id-8</th>\n",
       "      <th>id-9</th>\n",
       "      <th>id-10</th>\n",
       "      <th>id-11</th>\n",
       "      <th>id-12</th>\n",
       "      <th>id-13</th>\n",
       "      <th>id-14</th>\n",
       "      <th>id-15</th>\n",
       "      <th>id-16</th>\n",
       "      <th>id-17</th>\n",
       "      <th>id-18</th>\n",
       "      <th>id-19</th>\n",
       "      <th>id-20</th>\n",
       "      <th>id-21</th>\n",
       "      <th>id-22</th>\n",
       "      <th>id-23</th>\n",
       "      <th>id-24</th>\n",
       "      <th>id-25</th>\n",
       "      <th>id-26</th>\n",
       "      <th>id-27</th>\n",
       "      <th>id-28</th>\n",
       "      <th>id-29</th>\n",
       "      <th>id-30</th>\n",
       "      <th>id-31</th>\n",
       "      <th>id-32</th>\n",
       "      <th>id-33</th>\n",
       "      <th>id-34</th>\n",
       "      <th>id-35</th>\n",
       "      <th>id-36</th>\n",
       "      <th>id-37</th>\n",
       "      <th>id-38</th>\n",
       "      <th>id-39</th>\n",
       "      <th>...</th>\n",
       "      <th>id-60</th>\n",
       "      <th>id-61</th>\n",
       "      <th>id-62</th>\n",
       "      <th>id-63</th>\n",
       "      <th>id-64</th>\n",
       "      <th>id-65</th>\n",
       "      <th>id-66</th>\n",
       "      <th>id-67</th>\n",
       "      <th>id-68</th>\n",
       "      <th>id-69</th>\n",
       "      <th>id-70</th>\n",
       "      <th>id-71</th>\n",
       "      <th>id-72</th>\n",
       "      <th>id-73</th>\n",
       "      <th>id-74</th>\n",
       "      <th>id-75</th>\n",
       "      <th>id-76</th>\n",
       "      <th>id-77</th>\n",
       "      <th>id-78</th>\n",
       "      <th>id-79</th>\n",
       "      <th>id-80</th>\n",
       "      <th>id-81</th>\n",
       "      <th>id-82</th>\n",
       "      <th>id-83</th>\n",
       "      <th>id-84</th>\n",
       "      <th>id-85</th>\n",
       "      <th>id-86</th>\n",
       "      <th>id-87</th>\n",
       "      <th>id-88</th>\n",
       "      <th>id-89</th>\n",
       "      <th>id-90</th>\n",
       "      <th>id-91</th>\n",
       "      <th>id-92</th>\n",
       "      <th>id-93</th>\n",
       "      <th>id-94</th>\n",
       "      <th>id-95</th>\n",
       "      <th>id-96</th>\n",
       "      <th>id-97</th>\n",
       "      <th>id-98</th>\n",
       "      <th>id-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0,25)</td>\n",
       "      <td>1064</td>\n",
       "      <td>174</td>\n",
       "      <td>2791</td>\n",
       "      <td>3373</td>\n",
       "      <td>269</td>\n",
       "      <td>2678</td>\n",
       "      <td>1902</td>\n",
       "      <td>3641</td>\n",
       "      <td>1216</td>\n",
       "      <td>915</td>\n",
       "      <td>3672</td>\n",
       "      <td>2803</td>\n",
       "      <td>2344</td>\n",
       "      <td>986</td>\n",
       "      <td>3217</td>\n",
       "      <td>2824</td>\n",
       "      <td>2598</td>\n",
       "      <td>464</td>\n",
       "      <td>2340</td>\n",
       "      <td>1952</td>\n",
       "      <td>1855</td>\n",
       "      <td>1353</td>\n",
       "      <td>1547</td>\n",
       "      <td>3487</td>\n",
       "      <td>3293</td>\n",
       "      <td>1541</td>\n",
       "      <td>2414</td>\n",
       "      <td>2728</td>\n",
       "      <td>340</td>\n",
       "      <td>1421</td>\n",
       "      <td>1963</td>\n",
       "      <td>2545</td>\n",
       "      <td>972</td>\n",
       "      <td>487</td>\n",
       "      <td>3463</td>\n",
       "      <td>2727</td>\n",
       "      <td>1135</td>\n",
       "      <td>3135</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1010</td>\n",
       "      <td>1423</td>\n",
       "      <td>2840</td>\n",
       "      <td>1770</td>\n",
       "      <td>881</td>\n",
       "      <td>1913</td>\n",
       "      <td>1803</td>\n",
       "      <td>1734</td>\n",
       "      <td>3326</td>\n",
       "      <td>1617</td>\n",
       "      <td>224</td>\n",
       "      <td>3352</td>\n",
       "      <td>1869</td>\n",
       "      <td>1182</td>\n",
       "      <td>1331</td>\n",
       "      <td>336</td>\n",
       "      <td>2517</td>\n",
       "      <td>1721</td>\n",
       "      <td>3512</td>\n",
       "      <td>3656</td>\n",
       "      <td>273</td>\n",
       "      <td>1026</td>\n",
       "      <td>1991</td>\n",
       "      <td>2190</td>\n",
       "      <td>998</td>\n",
       "      <td>3386</td>\n",
       "      <td>3369</td>\n",
       "      <td>185</td>\n",
       "      <td>2822</td>\n",
       "      <td>864</td>\n",
       "      <td>2854</td>\n",
       "      <td>3067</td>\n",
       "      <td>58</td>\n",
       "      <td>2551</td>\n",
       "      <td>2333</td>\n",
       "      <td>2688</td>\n",
       "      <td>3703</td>\n",
       "      <td>1300</td>\n",
       "      <td>1924</td>\n",
       "      <td>3118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1,133)</td>\n",
       "      <td>1072</td>\n",
       "      <td>3154</td>\n",
       "      <td>3368</td>\n",
       "      <td>3644</td>\n",
       "      <td>549</td>\n",
       "      <td>1810</td>\n",
       "      <td>937</td>\n",
       "      <td>1514</td>\n",
       "      <td>1713</td>\n",
       "      <td>2186</td>\n",
       "      <td>660</td>\n",
       "      <td>2303</td>\n",
       "      <td>2416</td>\n",
       "      <td>670</td>\n",
       "      <td>1176</td>\n",
       "      <td>788</td>\n",
       "      <td>889</td>\n",
       "      <td>3120</td>\n",
       "      <td>2344</td>\n",
       "      <td>2525</td>\n",
       "      <td>3301</td>\n",
       "      <td>2055</td>\n",
       "      <td>1436</td>\n",
       "      <td>2630</td>\n",
       "      <td>11</td>\n",
       "      <td>2773</td>\n",
       "      <td>2176</td>\n",
       "      <td>1847</td>\n",
       "      <td>740</td>\n",
       "      <td>2332</td>\n",
       "      <td>3561</td>\n",
       "      <td>263</td>\n",
       "      <td>3658</td>\n",
       "      <td>3282</td>\n",
       "      <td>1980</td>\n",
       "      <td>2093</td>\n",
       "      <td>3287</td>\n",
       "      <td>3190</td>\n",
       "      <td>3475</td>\n",
       "      <td>...</td>\n",
       "      <td>2976</td>\n",
       "      <td>918</td>\n",
       "      <td>753</td>\n",
       "      <td>3540</td>\n",
       "      <td>3341</td>\n",
       "      <td>2973</td>\n",
       "      <td>1580</td>\n",
       "      <td>2118</td>\n",
       "      <td>3511</td>\n",
       "      <td>526</td>\n",
       "      <td>1719</td>\n",
       "      <td>525</td>\n",
       "      <td>1520</td>\n",
       "      <td>486</td>\n",
       "      <td>557</td>\n",
       "      <td>1353</td>\n",
       "      <td>500</td>\n",
       "      <td>2902</td>\n",
       "      <td>1687</td>\n",
       "      <td>1295</td>\n",
       "      <td>2997</td>\n",
       "      <td>2415</td>\n",
       "      <td>797</td>\n",
       "      <td>2518</td>\n",
       "      <td>926</td>\n",
       "      <td>3537</td>\n",
       "      <td>1746</td>\n",
       "      <td>1676</td>\n",
       "      <td>1875</td>\n",
       "      <td>3029</td>\n",
       "      <td>1535</td>\n",
       "      <td>341</td>\n",
       "      <td>3525</td>\n",
       "      <td>1429</td>\n",
       "      <td>2225</td>\n",
       "      <td>1628</td>\n",
       "      <td>2061</td>\n",
       "      <td>469</td>\n",
       "      <td>3056</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2,207)</td>\n",
       "      <td>2216</td>\n",
       "      <td>209</td>\n",
       "      <td>2347</td>\n",
       "      <td>3</td>\n",
       "      <td>1652</td>\n",
       "      <td>3397</td>\n",
       "      <td>383</td>\n",
       "      <td>2905</td>\n",
       "      <td>2284</td>\n",
       "      <td>2866</td>\n",
       "      <td>584</td>\n",
       "      <td>783</td>\n",
       "      <td>3208</td>\n",
       "      <td>1534</td>\n",
       "      <td>2529</td>\n",
       "      <td>1907</td>\n",
       "      <td>1170</td>\n",
       "      <td>3037</td>\n",
       "      <td>2015</td>\n",
       "      <td>1045</td>\n",
       "      <td>3099</td>\n",
       "      <td>3298</td>\n",
       "      <td>2522</td>\n",
       "      <td>739</td>\n",
       "      <td>2652</td>\n",
       "      <td>3702</td>\n",
       "      <td>792</td>\n",
       "      <td>2527</td>\n",
       "      <td>1945</td>\n",
       "      <td>2333</td>\n",
       "      <td>1668</td>\n",
       "      <td>3511</td>\n",
       "      <td>70</td>\n",
       "      <td>1991</td>\n",
       "      <td>3071</td>\n",
       "      <td>2474</td>\n",
       "      <td>1629</td>\n",
       "      <td>3221</td>\n",
       "      <td>505</td>\n",
       "      <td>...</td>\n",
       "      <td>1906</td>\n",
       "      <td>1812</td>\n",
       "      <td>1182</td>\n",
       "      <td>2831</td>\n",
       "      <td>1548</td>\n",
       "      <td>1630</td>\n",
       "      <td>2227</td>\n",
       "      <td>2352</td>\n",
       "      <td>760</td>\n",
       "      <td>350</td>\n",
       "      <td>302</td>\n",
       "      <td>791</td>\n",
       "      <td>300</td>\n",
       "      <td>3528</td>\n",
       "      <td>1444</td>\n",
       "      <td>2</td>\n",
       "      <td>798</td>\n",
       "      <td>997</td>\n",
       "      <td>376</td>\n",
       "      <td>2565</td>\n",
       "      <td>1565</td>\n",
       "      <td>718</td>\n",
       "      <td>710</td>\n",
       "      <td>2695</td>\n",
       "      <td>904</td>\n",
       "      <td>3643</td>\n",
       "      <td>655</td>\n",
       "      <td>3666</td>\n",
       "      <td>3069</td>\n",
       "      <td>3661</td>\n",
       "      <td>953</td>\n",
       "      <td>865</td>\n",
       "      <td>813</td>\n",
       "      <td>1353</td>\n",
       "      <td>2945</td>\n",
       "      <td>2580</td>\n",
       "      <td>2989</td>\n",
       "      <td>2790</td>\n",
       "      <td>2879</td>\n",
       "      <td>2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,208)</td>\n",
       "      <td>3023</td>\n",
       "      <td>1489</td>\n",
       "      <td>1916</td>\n",
       "      <td>1706</td>\n",
       "      <td>1221</td>\n",
       "      <td>1191</td>\n",
       "      <td>2671</td>\n",
       "      <td>81</td>\n",
       "      <td>2483</td>\n",
       "      <td>941</td>\n",
       "      <td>841</td>\n",
       "      <td>1617</td>\n",
       "      <td>1437</td>\n",
       "      <td>2700</td>\n",
       "      <td>1904</td>\n",
       "      <td>1763</td>\n",
       "      <td>1181</td>\n",
       "      <td>599</td>\n",
       "      <td>2442</td>\n",
       "      <td>1656</td>\n",
       "      <td>1370</td>\n",
       "      <td>1171</td>\n",
       "      <td>1372</td>\n",
       "      <td>1444</td>\n",
       "      <td>1596</td>\n",
       "      <td>2023</td>\n",
       "      <td>1456</td>\n",
       "      <td>2179</td>\n",
       "      <td>530</td>\n",
       "      <td>1949</td>\n",
       "      <td>2628</td>\n",
       "      <td>290</td>\n",
       "      <td>1996</td>\n",
       "      <td>2593</td>\n",
       "      <td>2489</td>\n",
       "      <td>3484</td>\n",
       "      <td>1035</td>\n",
       "      <td>2826</td>\n",
       "      <td>1274</td>\n",
       "      <td>...</td>\n",
       "      <td>3655</td>\n",
       "      <td>3073</td>\n",
       "      <td>557</td>\n",
       "      <td>2007</td>\n",
       "      <td>1937</td>\n",
       "      <td>2244</td>\n",
       "      <td>55</td>\n",
       "      <td>1016</td>\n",
       "      <td>2382</td>\n",
       "      <td>2506</td>\n",
       "      <td>3501</td>\n",
       "      <td>914</td>\n",
       "      <td>3127</td>\n",
       "      <td>23</td>\n",
       "      <td>3187</td>\n",
       "      <td>799</td>\n",
       "      <td>2572</td>\n",
       "      <td>1038</td>\n",
       "      <td>3028</td>\n",
       "      <td>2619</td>\n",
       "      <td>1429</td>\n",
       "      <td>2623</td>\n",
       "      <td>2158</td>\n",
       "      <td>2785</td>\n",
       "      <td>3674</td>\n",
       "      <td>2578</td>\n",
       "      <td>1837</td>\n",
       "      <td>1689</td>\n",
       "      <td>296</td>\n",
       "      <td>959</td>\n",
       "      <td>3347</td>\n",
       "      <td>1707</td>\n",
       "      <td>2901</td>\n",
       "      <td>2767</td>\n",
       "      <td>2167</td>\n",
       "      <td>1921</td>\n",
       "      <td>247</td>\n",
       "      <td>1618</td>\n",
       "      <td>2016</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4,222)</td>\n",
       "      <td>1794</td>\n",
       "      <td>3535</td>\n",
       "      <td>108</td>\n",
       "      <td>593</td>\n",
       "      <td>466</td>\n",
       "      <td>2048</td>\n",
       "      <td>854</td>\n",
       "      <td>1378</td>\n",
       "      <td>1301</td>\n",
       "      <td>697</td>\n",
       "      <td>1376</td>\n",
       "      <td>22</td>\n",
       "      <td>2135</td>\n",
       "      <td>3657</td>\n",
       "      <td>3173</td>\n",
       "      <td>1322</td>\n",
       "      <td>976</td>\n",
       "      <td>6</td>\n",
       "      <td>1399</td>\n",
       "      <td>817</td>\n",
       "      <td>2757</td>\n",
       "      <td>2010</td>\n",
       "      <td>652</td>\n",
       "      <td>458</td>\n",
       "      <td>1227</td>\n",
       "      <td>204</td>\n",
       "      <td>592</td>\n",
       "      <td>2875</td>\n",
       "      <td>1930</td>\n",
       "      <td>2251</td>\n",
       "      <td>1654</td>\n",
       "      <td>2542</td>\n",
       "      <td>1149</td>\n",
       "      <td>3089</td>\n",
       "      <td>454</td>\n",
       "      <td>2466</td>\n",
       "      <td>3461</td>\n",
       "      <td>1770</td>\n",
       "      <td>3106</td>\n",
       "      <td>...</td>\n",
       "      <td>3610</td>\n",
       "      <td>959</td>\n",
       "      <td>1927</td>\n",
       "      <td>2524</td>\n",
       "      <td>932</td>\n",
       "      <td>3327</td>\n",
       "      <td>187</td>\n",
       "      <td>2575</td>\n",
       "      <td>1674</td>\n",
       "      <td>557</td>\n",
       "      <td>2547</td>\n",
       "      <td>1572</td>\n",
       "      <td>776</td>\n",
       "      <td>1600</td>\n",
       "      <td>2682</td>\n",
       "      <td>2085</td>\n",
       "      <td>1987</td>\n",
       "      <td>1390</td>\n",
       "      <td>614</td>\n",
       "      <td>3098</td>\n",
       "      <td>1831</td>\n",
       "      <td>927</td>\n",
       "      <td>2285</td>\n",
       "      <td>1059</td>\n",
       "      <td>2850</td>\n",
       "      <td>3517</td>\n",
       "      <td>134</td>\n",
       "      <td>1852</td>\n",
       "      <td>2776</td>\n",
       "      <td>1694</td>\n",
       "      <td>2490</td>\n",
       "      <td>1332</td>\n",
       "      <td>2526</td>\n",
       "      <td>2804</td>\n",
       "      <td>2027</td>\n",
       "      <td>833</td>\n",
       "      <td>176</td>\n",
       "      <td>463</td>\n",
       "      <td>2851</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  (user_id, item_id)  id-1  id-2  id-3  id-4  ...  id-95  id-96  id-97  id-98  id-99\n",
       "0             (0,25)  1064   174  2791  3373  ...   2688   3703   1300   1924   3118\n",
       "1            (1,133)  1072  3154  3368  3644  ...   1628   2061    469   3056   2553\n",
       "2            (2,207)  2216   209  2347     3  ...   2580   2989   2790   2879   2481\n",
       "3            (3,208)  3023  1489  1916  1706  ...   1921    247   1618   2016   2323\n",
       "4            (4,222)  1794  3535   108   593  ...    833    176    463   2851   2453\n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpSIqUxAxAYc"
   },
   "source": [
    "The ml-1m.test.negative file is the test file for negative instances. Each line corresponds to the line of test.rating, containing 99 negative samples.\r\n",
    "Each line is in the format: (userID,itemID)\\t negativeItemID1\\t negativeItemID2 ...negativeItemID99. <br>\r\n",
    "For example, as we can see the first instance of test.rating is of user_id=0, item_id=25. For this pair we keep 99 negative items id's. Also here we will get that each user will only have one feedback record (followed by 99 negatives items ids)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrcmRMq51E09"
   },
   "source": [
    "# 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9JyRTNG2Q1l"
   },
   "source": [
    "The training dataset is created as following: <br> First we set num_negatives parameter. This parameter will define how many negative examples we add to our training set for each existing rating. <br> We initialize some empty matrix A. Then, we are iterating throguh our ratings matrix and for each user u that rated an item i: <br>\r\n",
    "* We add the corresponding positive instance for A, that is, we add (u, i, 1) (rating ~ positive interaction).\r\n",
    "* We are randomly selecting num_negatives items that the user u has *not* rated. For each such item j, we add the instance (u, j, 0) to A (movie that was not rated by a user ~ negative interaction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1OlsX1q2tbj"
   },
   "source": [
    "#1.c\r\n",
    "The testing data set is created in the same manner, only for the testing data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-wAG1AoV5VM"
   },
   "source": [
    "#2.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw1oPaKKZ1sk"
   },
   "source": [
    "Creating the implicit feedback training instances from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7kTjQbo9ZXl0"
   },
   "outputs": [],
   "source": [
    "num_items = len(training.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9keDZPrYV6dH"
   },
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\r\n",
    "    user_input, item_input, labels = [],[],[]\r\n",
    "    num_users = train.shape[0]\r\n",
    "    for i in range(len(train)):\r\n",
    "        if i % 50000 == 0:\r\n",
    "          print(i)\r\n",
    "        user = train.iloc[i].user_id\r\n",
    "        item = train.iloc[i].item_id\r\n",
    "        # positive instance\r\n",
    "        user_input.append(user)\r\n",
    "        item_input.append(item)\r\n",
    "        labels.append(1)\r\n",
    "        # negative instances\r\n",
    "        for t in range(num_negatives):\r\n",
    "            j = np.random.randint(num_items)\r\n",
    "            while not training[(training['user_id'] == user) & (training['item_id'] == j)].empty:\r\n",
    "                j = np.random.randint(num_items)\r\n",
    "            user_input.append(user)\r\n",
    "            item_input.append(j)\r\n",
    "            labels.append(0)\r\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsIp93rOWZJP",
    "outputId": "baf7bfac-caf8-4959-ed0f-3e44fd8f2880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n",
      "800000\n",
      "850000\n",
      "900000\n",
      "950000\n"
     ]
    }
   ],
   "source": [
    "train_instances = get_train_instances(training, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Gf4D9c1Gpyse"
   },
   "outputs": [],
   "source": [
    "users, items, labels = train_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQeEdsUEqp-I"
   },
   "source": [
    "Writing the implicit feedback training data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzApm9h7_nb4",
    "outputId": "ee95347e-50ac-4fd1-ed2f-26e83bc65b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "1200000\n",
      "1400000\n",
      "1600000\n",
      "1800000\n",
      "2000000\n",
      "2200000\n",
      "2400000\n",
      "2600000\n",
      "2800000\n",
      "3000000\n",
      "3200000\n",
      "3400000\n",
      "3600000\n",
      "3800000\n",
      "4000000\n",
      "4200000\n",
      "4400000\n",
      "4600000\n",
      "4800000\n"
     ]
    }
   ],
   "source": [
    "with open(f'training_data.csv', 'w') as f:\r\n",
    "    for i in range(len(users)):\r\n",
    "        if i % 200000 == 0:\r\n",
    "          print(i)\r\n",
    "        f.write(f'{users[i]}\\t{items[i]}\\t{labels[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XrW8LNgktYbC"
   },
   "outputs": [],
   "source": [
    "implicit_training_data = pd.read_csv('./training_data.csv', '\\t', names=['user_id', 'item_id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mgmJvsDtwGH",
    "outputId": "13a8e588-38f1-4aab-e68f-f77d81107ca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4970845, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "8t84Xzl2t1AL",
    "outputId": "ebde926f-b60e-4ff2-a689-48803e06da8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  label\n",
       "0        0       32      1\n",
       "1        0     2188      0\n",
       "2        0     2026      0\n",
       "3        0     1859      0\n",
       "4        0     3452      0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fpISINnBeVbc"
   },
   "outputs": [],
   "source": [
    "users, items, labels = list(implicit_training_data['user_id'].to_numpy()), list(implicit_training_data['item_id'].to_numpy()), list(implicit_training_data['label'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGljmXAMZ9f6"
   },
   "source": [
    "Defining the four models: MF, GMF, MLP and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1YD5gjiRKu0I"
   },
   "outputs": [],
   "source": [
    "# Learning Functions\n",
    "\n",
    "def gd(Y, U, V, reg, k, lr):\n",
    "    m = data['user_id']\n",
    "    n = data['item_id']\n",
    "    per = np.random.permutation(range(m.shape[0]))\n",
    "\n",
    "    for index in per:\n",
    "        i = m[index] - 1\n",
    "        j = n[index] - 1\n",
    "        grad_U = (reg * U[:,i]) - (V[:,j] * np.transpose(Y[i,j] - np.dot(np.transpose(U[:,i]), V[:,j])))\n",
    "        grad_V = (reg * V[:,j]) - (U[:,i] * np.transpose(Y[i,j] - np.dot(np.transpose(U[:,i]), V[:,j])))\n",
    "        U[:,i] -= lr * grad_U\n",
    "        V[:,j] -= lr * grad_V\n",
    "        \n",
    "    return U, V\n",
    "\n",
    "def als(Y, fixed, k, reg):\n",
    "  A = fixed.dot(fixed.T) + np.eye(k) * reg\n",
    "  b = fixed.dot(Y.T)\n",
    "  A_inv = np.linalg.inv(A)\n",
    "  solved = b.T.dot(A_inv)\n",
    "  return solved.T\n",
    "\n",
    "\n",
    "# Loss Functions\n",
    "\n",
    "def rmse_loss(Y, U, V):    \n",
    "    m = Y.shape[0]\n",
    "    n = Y.shape[1]\n",
    "    index = (Y != 0)\n",
    "    Y_hat = np.dot(np.transpose(U), V)\n",
    "    return (1 / (m * n)) * np.sum(np.square(Y[index] - Y_hat[index]))\n",
    "\n",
    "def mrr_score(Y, U, V, threshold=3, cutoff=5):\n",
    "  index = (Y != 0)\n",
    "  Y_hat= np.dot(np.transpose(U), V)\n",
    "  _mrr = []\n",
    "  for user in range(len(Y_hat)):\n",
    "    _top_ratings_indexes = [i[0] for i in sorted(enumerate(Y_hat[user]), key=lambda x:x[1], reverse=True)]\n",
    "    idx = 1\n",
    "    for item in _top_ratings_indexes[:cutoff]:\n",
    "      if Y[user, data['item_id'][item]-1] >= threshold:\n",
    "        _mrr.append(1/idx)\n",
    "      idx += 1\n",
    "  return np.mean(_mrr)\n",
    "\n",
    "def dcg(ratings):\n",
    "    dcg = []\n",
    "    for idx, val in enumerate(ratings): \n",
    "        numerator = 2**val - 1\n",
    "        denominator =  np.log2(idx + 2) \n",
    "        score = numerator / denominator\n",
    "        dcg.append(score)\n",
    "    return sum(dcg)\n",
    "\n",
    "def ndcg(Y, U, V, cutoff=10):\n",
    "    Y_hat= np.dot(np.transpose(U), V)\n",
    "    ndcgs = []\n",
    "    for user in range(len(Y_hat)):\n",
    "      _items = []\n",
    "      _top_ratings_indexes = [i[0] for i in sorted(enumerate(Y_hat[user]), key=lambda x:x[1], reverse=True)]\n",
    "      for item in _top_ratings_indexes[:cutoff]:\n",
    "        _items.append(Y[user, data['item_id'][item]-1])\n",
    "      _dcg = dcg(_items)\n",
    "      sorted_items = sorted(_items)\n",
    "      idcg = dcg(sorted_items)\n",
    "      if idcg > 0:\n",
    "        ndcg = _dcg / idcg\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.mean(ndcgs) # average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TbH20YwRK0Ha"
   },
   "outputs": [],
   "source": [
    "def MF(learning_func, score_loss_func, k, reg, lr, num_epochs, test):\n",
    "    U = np.random.rand(k, num_users)\n",
    "    V = np.random.rand(k, num_items)\n",
    "\n",
    "    # missing samples is zero\n",
    "    Y = np.zeros([num_users, num_items], dtype = 'float64')\n",
    "    Y_test = np.zeros([num_users, num_items], dtype = 'float64')\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        Y[data['user_id'][i]-1, data['item_id'][i]-1] = data['rating'][i]\n",
    "\n",
    "    for i in range(0, len(test)):\n",
    "      Y_test[test['user_id'][i]-1, test['item_id'][i]-1] = test['rating'][i]\n",
    "      Y[test['user_id'][i]-1, test['item_id'][i]-1] = 0.0 # delete the test from train data\n",
    "\n",
    "    scores_losses = []\n",
    "\n",
    "    for e in range(1, num_epochs + 1):\n",
    "        score_loss = 0\n",
    "        if learning_func == 'gd':\n",
    "          U, V = gd(Y, U, V, reg, k, lr)\n",
    "        if learning_func == 'als':\n",
    "          U = als(Y, V, k, reg)\n",
    "          V = als(Y.T, U, k, reg)\n",
    "        score_loss = score_loss_func(Y, U, V)\n",
    "        scores_losses.append(score_loss)\n",
    "\n",
    "    test_score_loss = score_loss_func(Y_test, U, V)\n",
    "    return test_score_loss, scores_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xxV12SEeZObB"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, Reshape,  Flatten, Dropout\r\n",
    "from keras.regularizers import l2\r\n",
    "from keras import backend as K\r\n",
    "from keras import initializers\r\n",
    "from keras.initializers import RandomNormal\r\n",
    "from keras.models import Sequential, Model, load_model, save_model\r\n",
    "from keras.layers.core import Dense, Lambda, Activation\r\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\r\n",
    "from keras.layers import Multiply, Concatenate\r\n",
    "\r\n",
    "def get_GMF_model(num_users, num_items, latent_dim, regs=[[0,0]]):\r\n",
    "    #Generalized Matrix Factorization\r\n",
    "    \r\n",
    "    # Input variables\r\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
    "\r\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \r\n",
    "    \r\n",
    "    # Crucial to flatten an embedding vector!\r\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\r\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\r\n",
    "    \r\n",
    "    # Element-wise product of user and item embeddings \r\n",
    "    predict_vector = Multiply()([user_latent, item_latent]) #merge([user_latent, item_latent], mode = 'mul')\r\n",
    "    \r\n",
    "    # Final prediction layer\r\n",
    "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(predict_vector)\r\n",
    "    \r\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def get_MLP_model(num_users, num_items, latent_dim, regs=[[0,0],0,0], layers = [20,10]):\r\n",
    "    #Multi-Layer Perceptron\r\n",
    "    \r\n",
    "    assert len(layers) + 1 == len(regs), 'the number of regs is equal to number of layers + the embedding layer'\r\n",
    "    num_layer = len(layers) #Number of layers in the MLP\r\n",
    "    # Input variables\r\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
    "\r\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    \r\n",
    "    # Crucial to flatten an embedding vector!\r\n",
    "    user_latent = Flatten()(MLP_Embedding_User(user_input))\r\n",
    "    item_latent = Flatten()(MLP_Embedding_Item(item_input))\r\n",
    "    \r\n",
    "    # Concatenation of embedding layers\r\n",
    "    vector = Concatenate(axis=-1)([user_latent, item_latent])#merge([user_latent, item_latent], mode = 'concat')\r\n",
    "    \r\n",
    "    # MLP layers\r\n",
    "    for idx in range(num_layer):\r\n",
    "        layer = Dense(layers[idx], kernel_regularizer = l2(regs[idx+1]), activation='relu', name = 'layer%d' %idx)\r\n",
    "        vector = layer(vector)\r\n",
    "        \r\n",
    "    # Final prediction layer\r\n",
    "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(vector)\r\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
    "    return model\r\n",
    "\r\n",
    "def get_NMF_model(num_users, num_items, latent_dim_GMF, latent_dim_MLP, reg_GMF=[[0,0]], regs_MLP=[[0,0],0,0], layers=[20,10]):\r\n",
    "    #Neural matrix factorization\r\n",
    "    assert len(layers) + 1 == len(regs_MLP), 'the number of regs is equal to number of layers + the embedding layer'\r\n",
    "    num_layer = len(layers) #Number of layers in the MLP\r\n",
    "\r\n",
    "    # Input variables\r\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
    "    \r\n",
    "    # Embedding layer\r\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_GMF, name = 'MF_user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_GMF, name = 'MF_item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \r\n",
    "    \r\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_MLP, name = 'MLP_user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_MLP, name = 'MLP_item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    \r\n",
    "    # MF part\r\n",
    "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\r\n",
    "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\r\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) #merge([mf_user_latent, mf_item_latent], mode = 'mul') # element-wise multiply\r\n",
    "\r\n",
    "    # MLP part \r\n",
    "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\r\n",
    "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\r\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])#merge([mlp_user_latent, mlp_item_latent], mode = 'concat')\r\n",
    "    for idx in range(num_layer):\r\n",
    "        layer =  Dense(layers[idx], kernel_regularizer = l2(regs_MLP[idx+1]), activation='tanh', name = 'layer%d' %idx)\r\n",
    "        mlp_vector = layer(mlp_vector)\r\n",
    "\r\n",
    "    # Concatenate MF and MLP parts\r\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\r\n",
    "    \r\n",
    "    # Final prediction layer\r\n",
    "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)    \r\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
    "    \r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM3tiCcbuHVd"
   },
   "source": [
    "#2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO043nAPG6gx"
   },
   "source": [
    "Defining some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6nicmwM9k8TW"
   },
   "outputs": [],
   "source": [
    "num_factors = 8 #size of embedding size. Can be split to 4 different params potentially.\r\n",
    "num_negatives = 4 #how many negative samples per positive sample?\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 256\r\n",
    "verbose = 1\r\n",
    "\r\n",
    "topK = 10 #used to evaluate the model. Top K recommendations are used. \r\n",
    "num_users = len(implicit_training_data.user_id.unique())\r\n",
    "num_items = len(implicit_training_data.item_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY9WoDN3JwZY"
   },
   "source": [
    "Defining evaluation utilities (including MRR and NDCG metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OAJq4cGSwZpx"
   },
   "outputs": [],
   "source": [
    "import math\r\n",
    "import heapq # for retrieval topK\r\n",
    "from time import time\r\n",
    "\r\n",
    "def evaluate_model(model, testRatings, testNegatives, K):\r\n",
    "    \"\"\"\r\n",
    "    Evaluate the performance (MRR, NDCG) of top-K recommendation\r\n",
    "    Return: score of each test rating.\r\n",
    "    \"\"\" \r\n",
    "    mrrs, ndcgs = [],[]\r\n",
    "    # Single thread\r\n",
    "    for idx in range(len(testRatings)):\r\n",
    "        (mrr,ndcg) = eval_one_rating(model, testRatings, testNegatives, idx, K)\r\n",
    "        mrrs.append(mrr)\r\n",
    "        ndcgs.append(ndcg)      \r\n",
    "    return (mrrs, ndcgs)\r\n",
    "\r\n",
    "def eval_one_rating(model, testRatings, testNegatives, idx, K):\r\n",
    "    rating = testRatings.iloc[idx]['rating']\r\n",
    "    u = testRatings.iloc[idx]['user_id']\r\n",
    "    gtItem = testRatings.iloc[idx]['item_id']\r\n",
    "    items = testNegatives[testNegatives['(user_id, item_id)'] == f'({u},{gtItem})'].to_numpy()[0]\r\n",
    "    items = items[1:len(items)].astype('int32')\r\n",
    "    items = np.append(items, gtItem)\r\n",
    "    users = np.full(len(items), u, dtype = 'int32')\r\n",
    "    # Get prediction scores\r\n",
    "    map_item_score = {}\r\n",
    "    predictions = model.predict([users, items], \r\n",
    "                                 batch_size=100, verbose=0)\r\n",
    "    for i in range(len(items)):\r\n",
    "        item = items[i]\r\n",
    "        map_item_score[item] = predictions[i]\r\n",
    "    items = items[0:len(items)-1]\r\n",
    "    \r\n",
    "    # Evaluate top rank list\r\n",
    "    ranklist = heapq.nlargest(K, map_item_score, key=map_item_score.get)\r\n",
    "    mrr = getMRR(ranklist, gtItem)\r\n",
    "    ndcg = getNDCG(ranklist, gtItem)\r\n",
    "    return (mrr, ndcg)\r\n",
    "\r\n",
    "\r\n",
    "def getMRR(ranklist, gtItem):\r\n",
    "  for i in range(0, len(ranklist)):\r\n",
    "    if ranklist[i] == gtItem:\r\n",
    "      return 1/(i+1)\r\n",
    "\r\n",
    "  return 0\r\n",
    "\r\n",
    "def getNDCG(ranklist, gtItem):\r\n",
    "    for i in range(len(ranklist)):\r\n",
    "        item = ranklist[i]\r\n",
    "        if item == gtItem:\r\n",
    "            return math.log(2) / math.log(i+2)\r\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7GeBLBAJ6i_"
   },
   "source": [
    "Initializing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5Cdrc6jWHXaW"
   },
   "outputs": [],
   "source": [
    "# Build models\r\n",
    "gmf_model = get_GMF_model(num_users, num_items, num_factors, regs = [[0,0]])\r\n",
    "mlp_model = get_MLP_model(num_users, num_items, num_factors, regs = [[0,0],0,0,0], layers = [32,16,8])\r\n",
    "nmf_model = get_NMF_model(num_users, num_items, latent_dim_GMF=num_factors, latent_dim_MLP=num_factors, reg_GMF=[[0,0]],\r\n",
    "                      regs_MLP=[[0,0],0,0,0], layers=[32,16,8])\r\n",
    "\r\n",
    "gmf_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\r\n",
    "mlp_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\r\n",
    "nmf_model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qymCSO1nIjo4"
   },
   "source": [
    "**Init performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MkqzB8mTuVZj"
   },
   "outputs": [],
   "source": [
    "models = [('GMF', gmf_model), ('MLP', mlp_model), ('NMF', nmf_model)]\r\n",
    "def initPerformance():\r\n",
    "  # Init performance\r\n",
    "  for name, model in models:\r\n",
    "    start = time()\r\n",
    "    (mrrs, ndcgs) = evaluate_model(model, test_rating, test_negative, topK)\r\n",
    "    mrr, ndcg = np.array(mrrs).mean(), np.array(ndcgs).mean()\r\n",
    "    print(f'{name} Init: MRR = {mrr}, NDCG =  {ndcg}, Time (minutes):  {(time()-start)/60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDkaLSWTJSVK",
    "outputId": "48508f9a-931c-4e36-d49a-8627ecb62289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMF Init: MRR = 0.027220316934720906, NDCG =  0.04289594653594933, Time (minutes):  2.9573014775911965\n",
      "MLP Init: MRR = 0.028513612950699044, NDCG =  0.04417181337208131, Time (minutes):  2.9358290076255797\n",
      "NMF Init: MRR = 0.03379802638494691, NDCG =  0.05189504976179986, Time (minutes):  2.9414419452349345\n"
     ]
    }
   ],
   "source": [
    "initPerformance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWGdW_rRh4qw"
   },
   "source": [
    "**Training and evaluating performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jFqg5RTw61l_"
   },
   "outputs": [],
   "source": [
    "def train_evaluate_models(epochs=10):\r\n",
    "  # Train model\r\n",
    "  for name, model in models:\r\n",
    "    for topK in [5, 10]:\r\n",
    "      print(f'\\n{name} Model: cutoff = {topK}\\n')\r\n",
    "      for epoch in range(1, epochs + 1):\r\n",
    "\r\n",
    "        start = time()\r\n",
    "        # Generate training instances\r\n",
    "        user_input, item_input = users, items\r\n",
    "\r\n",
    "        # Training\r\n",
    "        hist = model.fit([np.array(user_input), np.array(item_input)], #input\r\n",
    "                          np.array(labels), # labels \r\n",
    "                          batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\r\n",
    "        loss = hist.history['loss'][0]\r\n",
    "        if epoch % 5 == 0:\r\n",
    "          # Evaluation\r\n",
    "          (mrrs, ndcgs) = evaluate_model(model, test_rating, test_negative, topK)\r\n",
    "\r\n",
    "          end = time()\r\n",
    "\r\n",
    "          mrr, ndcg = np.array(mrrs).mean(), np.array(ndcgs).mean() \r\n",
    "          print(f'[Epoch: {epoch}, Time (minutes): {(end-start) / 60}, Test MRR = {mrr}, Test NDCG = {ndcg}, Loss = {loss}]')\r\n",
    "\r\n",
    "        else:\r\n",
    "          print(f'[Epoch: {epoch}, Loss = {loss}]')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwZgW9hHEtCj",
    "outputId": "c310d66a-7792-4487-ed21-e6b927a7cd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GMF Model: cutoff = 5\n",
      "\n",
      "[Epoch: 1, Loss = 0.3628537058830261]\n",
      "[Epoch: 2, Loss = 0.307639479637146]\n",
      "[Epoch: 3, Loss = 0.28916656970977783]\n",
      "[Epoch: 4, Loss = 0.27786773443222046]\n",
      "[Epoch: 5, Time (minutes): 3.693118929862976, Test MRR = 0.2447488962472406, Test NDCG = 0.2913974783392471, Loss = 0.27368664741516113]\n",
      "[Epoch: 6, Loss = 0.2717829644680023]\n",
      "[Epoch: 7, Loss = 0.27060410380363464]\n",
      "[Epoch: 8, Loss = 0.2698017656803131]\n",
      "[Epoch: 9, Loss = 0.2691515386104584]\n",
      "[Epoch: 10, Time (minutes): 3.6946535229682924, Test MRR = 0.25068708609271523, Test NDCG = 0.2990442014220135, Loss = 0.26864802837371826]\n",
      "\n",
      "GMF Model: cutoff = 10\n",
      "\n",
      "[Epoch: 1, Loss = 0.26818034052848816]\n",
      "[Epoch: 2, Loss = 0.2678431272506714]\n",
      "[Epoch: 3, Loss = 0.2674868702888489]\n",
      "[Epoch: 4, Loss = 0.2671961784362793]\n",
      "[Epoch: 5, Time (minutes): 3.8103481690088907, Test MRR = 0.2761968490486702, Test NDCG = 0.3581624982618208, Loss = 0.2669491171836853]\n",
      "[Epoch: 6, Loss = 0.2666969895362854]\n",
      "[Epoch: 7, Loss = 0.26646482944488525]\n",
      "[Epoch: 8, Loss = 0.266296923160553]\n",
      "[Epoch: 9, Loss = 0.2660941779613495]\n",
      "[Epoch: 10, Time (minutes): 3.737181003888448, Test MRR = 0.27554839430253336, Test NDCG = 0.35875492163310935, Loss = 0.26593631505966187]\n",
      "\n",
      "MLP Model: cutoff = 5\n",
      "\n",
      "[Epoch: 1, Loss = 0.3496323823928833]\n",
      "[Epoch: 2, Loss = 0.3135554790496826]\n",
      "[Epoch: 3, Loss = 0.29670625925064087]\n",
      "[Epoch: 4, Loss = 0.2883375287055969]\n",
      "[Epoch: 5, Time (minutes): 3.8687233289082843, Test MRR = 0.24038079470198678, Test NDCG = 0.28574172223814426, Loss = 0.28297969698905945]\n",
      "[Epoch: 6, Loss = 0.27954524755477905]\n",
      "[Epoch: 7, Loss = 0.27719777822494507]\n",
      "[Epoch: 8, Loss = 0.2753424644470215]\n",
      "[Epoch: 9, Loss = 0.2738587558269501]\n",
      "[Epoch: 10, Time (minutes): 3.8834068338076273, Test MRR = 0.24826986754966887, Test NDCG = 0.29470802872140905, Loss = 0.2726684510707855]\n",
      "\n",
      "MLP Model: cutoff = 10\n",
      "\n",
      "[Epoch: 1, Loss = 0.2716565430164337]\n",
      "[Epoch: 2, Loss = 0.2707903981208801]\n",
      "[Epoch: 3, Loss = 0.2700720429420471]\n",
      "[Epoch: 4, Loss = 0.26939600706100464]\n",
      "[Epoch: 5, Time (minutes): 3.874358054002126, Test MRR = 0.27464436823294436, Test NDCG = 0.3554127244071582, Loss = 0.2687910199165344]\n",
      "[Epoch: 6, Loss = 0.268214613199234]\n",
      "[Epoch: 7, Loss = 0.2677016854286194]\n",
      "[Epoch: 8, Loss = 0.26731064915657043]\n",
      "[Epoch: 9, Loss = 0.2668933570384979]\n",
      "[Epoch: 10, Time (minutes): 3.947980531056722, Test MRR = 0.2735633475244402, Test NDCG = 0.3550554179701458, Loss = 0.26650741696357727]\n",
      "\n",
      "NMF Model: cutoff = 5\n",
      "\n",
      "[Epoch: 1, Loss = 0.31959056854248047]\n",
      "[Epoch: 2, Loss = 0.27589151263237]\n",
      "[Epoch: 3, Loss = 0.2660347521305084]\n",
      "[Epoch: 4, Loss = 0.26109930872917175]\n",
      "[Epoch: 5, Time (minutes): 4.043242665131887, Test MRR = 0.2671881898454746, Test NDCG = 0.31691578002460774, Loss = 0.2579744756221771]\n",
      "[Epoch: 6, Loss = 0.25577089190483093]\n",
      "[Epoch: 7, Loss = 0.2539215385913849]\n",
      "[Epoch: 8, Loss = 0.2524237334728241]\n",
      "[Epoch: 9, Loss = 0.2511700391769409]\n",
      "[Epoch: 10, Time (minutes): 4.008650092283885, Test MRR = 0.27180187637969094, Test NDCG = 0.3213800783556247, Loss = 0.25006431341171265]\n",
      "\n",
      "NMF Model: cutoff = 10\n",
      "\n",
      "[Epoch: 1, Loss = 0.24905717372894287]\n",
      "[Epoch: 2, Loss = 0.2481912523508072]\n",
      "[Epoch: 3, Loss = 0.24742631614208221]\n",
      "[Epoch: 4, Loss = 0.24667488038539886]\n",
      "[Epoch: 5, Time (minutes): 4.133106064796448, Test MRR = 0.2940666062230632, Test NDCG = 0.3772991650822703, Loss = 0.24606962502002716]\n",
      "[Epoch: 6, Loss = 0.24547521770000458]\n",
      "[Epoch: 7, Loss = 0.2449348121881485]\n",
      "[Epoch: 8, Loss = 0.2444235384464264]\n",
      "[Epoch: 9, Loss = 0.24396583437919617]\n",
      "[Epoch: 10, Time (minutes): 4.23122173945109, Test MRR = 0.29202991958372754, Test NDCG = 0.3748068414685748, Loss = 0.24354223906993866]\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGG5qG0QF-3F"
   },
   "source": [
    "**Comparsion:**\r\n",
    "\r\n",
    "*   First of all, as we can see, for all three models, we got better results when using a cutoff of 10 comparing to when we used a cutoff of 5. This is true regarding both MRR and NDCG metrics. \r\n",
    "*   When comparing between the three models (MLP, GMF, NMF), we can see that the best results achieved when using NMF model (this is true for both MRR and NDCG metrics).\r\n",
    "* The results for MLP and GMF are quite similar. GMF got better result w.r.t MRR metric, and MLP got better results w.r.t to NDCG metric.\r\n",
    "* For all three models, we can clearly see that the learning process is more efficient when using a cutoff = 5. That is, we are having a better improvement  relative to the starting point (in terms of loss) and we manage to decrease the loss more quickly and intensively with this cutoff.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG5FENr7OfOw"
   },
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f1CC9a_P52K"
   },
   "source": [
    "Both the MRR and NDCG metrics are used as a measures for evaluating the ordered output of a model. The order of the output (the list of items) is by most relevant to the least relevant item. Since in this exercise we use an implicit ranking, there is not such thing as “more relevant” and “less relevant”, because every items that the user has ranked we consider as relevant (‘1’) and every items that was not been ranked we consider as not relevant (‘0’). In conclusion, using the MRR and NDCG metrics for evaluating measures in the implicit case is less accurate since the basic assumption - that the order of the items are relevant - does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECndOS0VOhOb"
   },
   "source": [
    "# 2.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2YySsn-XwyZ"
   },
   "source": [
    "We suggest the following method for representing an item and measuring item similarity using NeuMF model: for every user u and item i, use the NeuMF model which outputs y_ui. For an item I create a vector which contains all the outputs y_ui for all the users u in U (set of users), in a predefined order. The, for two items i_1 and i_2, we will use their vectors to calculate their cosine similarity score. We do expect this method to be a reliable way to measure items similarity, because the basic assumption is that similar items will get similar relevancy score for each user, so their vectors (or their angle) will be similar, resulting in high cosine similary score (close to 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBzZjICXKkBd"
   },
   "source": [
    "#3.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9AEb2O8NiW4"
   },
   "source": [
    "We will define the NMF model from new, with RELU as last activation function and loss set to MSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jeueC3ZMKlbt"
   },
   "outputs": [],
   "source": [
    "def get_NMF_model_2(num_users, num_items, latent_dim_GMF, latent_dim_MLP, reg_GMF=[[0,0]], regs_MLP=[[0,0],0,0], layers=[20,10]):\r\n",
    "    #Neural matrix factorization\r\n",
    "    assert len(layers) + 1 == len(regs_MLP), 'the number of regs is equal to number of layers + the embedding layer'\r\n",
    "    num_layer = len(layers) #Number of layers in the MLP\r\n",
    "\r\n",
    "    # Input variables\r\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\r\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\r\n",
    "    \r\n",
    "    # Embedding layer\r\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_GMF, name = 'MF_user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_GMF, name = 'MF_item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(reg_GMF[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01))  #init = init_normal, \r\n",
    "    \r\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim_MLP, name = 'MLP_user_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][0]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim_MLP, name = 'MLP_item_embedding',\r\n",
    "                                   embeddings_regularizer = l2(regs_MLP[0][1]), input_length=1,embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01)) #init = init_normal,\r\n",
    "    \r\n",
    "    # MF part\r\n",
    "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\r\n",
    "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\r\n",
    "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) #merge([mf_user_latent, mf_item_latent], mode = 'mul') # element-wise multiply\r\n",
    "\r\n",
    "    # MLP part \r\n",
    "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\r\n",
    "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\r\n",
    "    mlp_vector = Concatenate(axis=-1)([mlp_user_latent, mlp_item_latent])#merge([mlp_user_latent, mlp_item_latent], mode = 'concat')\r\n",
    "    for idx in range(num_layer):\r\n",
    "        layer =  Dense(layers[idx], kernel_regularizer = l2(regs_MLP[idx+1]), activation='tanh', name = 'layer%d' %idx)\r\n",
    "        mlp_vector = layer(mlp_vector)\r\n",
    "\r\n",
    "    # Concatenate MF and MLP parts\r\n",
    "    predict_vector = Concatenate(axis=-1)([mf_vector, mlp_vector])\r\n",
    "    \r\n",
    "    # Final prediction layer\r\n",
    "    # Changed from sigmoid to RELU.\r\n",
    "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)    \r\n",
    "    model = Model(inputs=[user_input, item_input], outputs=prediction)\r\n",
    "    \r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8nCDNndN9nx"
   },
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUM8b6GuLBaU",
    "outputId": "67e96664-d602-4007-fb8c-de7db54a9d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MLP_user_embedding (Embedding)  (None, 1, 8)         48320       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MLP_item_embedding (Embedding)  (None, 1, 8)         29648       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 8)            0           MLP_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 8)            0           MLP_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16)           0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MF_user_embedding (Embedding)   (None, 1, 8)         48320       user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MF_item_embedding (Embedding)   (None, 1, 8)         29648       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 32)           544         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 8)            0           MF_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 8)            0           MF_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 16)           528         layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 8)            0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 8)            136         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16)           0           multiply_2[0][0]                 \n",
      "                                                                 layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 157,161\n",
      "Trainable params: 157,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nmf_model_2 = get_NMF_model_2(num_users, num_items, latent_dim_GMF=num_factors, latent_dim_MLP=num_factors, reg_GMF=[[0,0]],\r\n",
    "                      regs_MLP=[[0,0],0,0,0], layers=[32,16,8])\r\n",
    "nmf_model_2.compile(optimizer=Adam(lr=learning_rate), loss='mse')\r\n",
    "print(nmf_model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTMxpDi0N_-U"
   },
   "source": [
    "Learning for 10 epochs (as before) and outputting the metrics evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSjGSDxKLsON",
    "outputId": "19084db1-795e-489a-dadb-4d3213fdc648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF Model (with RELU and MSE loss):\n",
      "\n",
      "\n",
      "cutoff = 5\n",
      "\n",
      "[Epoch: 1, Loss = 0.09962603449821472]\n",
      "[Epoch: 2, Loss = 0.08714807033538818]\n",
      "[Epoch: 3, Loss = 0.08440519124269485]\n",
      "[Epoch: 4, Loss = 0.0829232707619667]\n",
      "[Epoch: 5, Time (minutes): 3.9858445564905804, Test MRR = 0.2618846578366446, Test NDCG = 0.3107282478360862, Loss = 0.08188372105360031]\n",
      "[Epoch: 6, Loss = 0.08101693540811539]\n",
      "[Epoch: 7, Loss = 0.08027520775794983]\n",
      "[Epoch: 8, Loss = 0.07961497455835342]\n",
      "[Epoch: 9, Loss = 0.07904289662837982]\n",
      "[Epoch: 10, Time (minutes): 3.9726574778556825, Test MRR = 0.2679470198675497, Test NDCG = 0.31796025532737815, Loss = 0.07855463773012161]\n",
      "\n",
      "cutoff = 10\n",
      "\n",
      "[Epoch: 1, Loss = 0.07813173532485962]\n",
      "[Epoch: 2, Loss = 0.07780124247074127]\n",
      "[Epoch: 3, Loss = 0.07747158408164978]\n",
      "[Epoch: 4, Loss = 0.07721131294965744]\n",
      "[Epoch: 5, Time (minutes): 4.016893311341604, Test MRR = 0.28702045884578997, Test NDCG = 0.371383434170011, Loss = 0.07695277780294418]\n",
      "[Epoch: 6, Loss = 0.07672039419412613]\n",
      "[Epoch: 7, Loss = 0.07650771737098694]\n",
      "[Epoch: 8, Loss = 0.07631997764110565]\n",
      "[Epoch: 9, Loss = 0.07613325864076614]\n",
      "[Epoch: 10, Time (minutes): 3.9760215282440186, Test MRR = 0.28302940712708924, Test NDCG = 0.3670071022429074, Loss = 0.07597649842500687]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nNMF Model (with RELU and MSE loss):\\n')\r\n",
    "for topK in [5, 10]:\r\n",
    "  print(f'\\ncutoff = {topK}\\n')\r\n",
    "  for epoch in range(1, 11):\r\n",
    "\r\n",
    "    start = time()\r\n",
    "    # Generate training instances\r\n",
    "    user_input, item_input = users, items\r\n",
    "\r\n",
    "    # Training\r\n",
    "    hist = nmf_model_2.fit([np.array(user_input), np.array(item_input)], #input\r\n",
    "                      np.array(labels), # labels \r\n",
    "                      batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\r\n",
    "    loss = hist.history['loss'][0]\r\n",
    "    if epoch % 5 == 0:\r\n",
    "      # Evaluation\r\n",
    "      (mrrs, ndcgs) = evaluate_model(nmf_model_2, test_rating, test_negative, topK)\r\n",
    "\r\n",
    "      end = time()\r\n",
    "\r\n",
    "      mrr, ndcg = np.array(mrrs).mean(), np.array(ndcgs).mean() \r\n",
    "      print(f'[Epoch: {epoch}, Time (minutes): {(end-start) / 60}, Test MRR = {mrr}, Test NDCG = {ndcg}, Loss = {loss}]')\r\n",
    "\r\n",
    "    else:\r\n",
    "      print(f'[Epoch: {epoch}, Loss = {loss}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfl02oauNhMs"
   },
   "source": [
    "As we can see, we got very similar results to the ones we got with the original NMF implementation. We get almost the same scores both for NDCG and MRR metrics, for both settings of the cutoff (5, 10). Of course the loss is different, but this is because we use a different loss function (MSE). In general, sigmoid function restricts each neuron to be in (0,1), which may limit the model’s performance; and it is known to suffer from saturation, where neurons stop learning when their output is near either 0 or 1. RELU on the other hand, was proven to be non-saturated. Moreover, it encourages sparse activations, being well-suited for sparse data and making the model less likely to be overfitting."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RS_Ass3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
