{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_dir = './ml-100k/'\n",
    "\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']   \n",
    "df = pd.read_csv(f'{folds_dir}u.data', sep='\\t', names=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_users_and_items():\n",
    "    header = ['user_id', 'item_id', 'rating', 'timestamp']   \n",
    "    df = pd.read_csv(f'{folds_dir}u.data', sep='\\t', names=header)\n",
    "    users = df.user_id.unique()\n",
    "    items = df.item_id.unique()\n",
    "    return users, items\n",
    "all_users_ids, all_items_ids = get_all_users_and_items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_rating_matrix_from_raw_data(df):\n",
    "\n",
    "    ratings = np.zeros((all_users_ids.shape[0], all_items_ids.shape[0]))\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        ratings[row[1]-1][row[2]-1] = row[3]  \n",
    "        \n",
    "    return ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{folds_dir}u.data', sep='\\t', names=header)\n",
    "df.shape\n",
    "\n",
    "ratings = create_rating_matrix_from_raw_data(df)\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sparsity = float(len(np.nan_to_num(ratings).nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_5_folds(folds_dir='./ml-100k/'):    \n",
    "    header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    folds = []\n",
    "    \n",
    "    for i in range(5):     \n",
    "        print(f'{folds_dir}u{i+1}.base')\n",
    "        df_train = pd.read_csv(f'{folds_dir}u{i+1}.base', sep='\\t', names=header)\n",
    "        df_test = pd.read_csv(f'{folds_dir}u{i+1}.test', sep='\\t', names=header)   \n",
    "        \n",
    "        rating_train = create_rating_matrix_from_raw_data(df_train)\n",
    "        rating_test  = create_rating_matrix_from_raw_data(df_test)        \n",
    "           \n",
    "        folds.append((rating_train, rating_test))\n",
    "    return folds\n",
    "folds = get_5_folds()\n",
    "\n",
    "for fold in folds:\n",
    "    print(fold[0].shape, fold[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = folds[0]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "import numpy as np\n",
    "\n",
    "class ExplicitMF():\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 n_factors=40,\n",
    "                 item_reg=0.0,\n",
    "                 user_reg=0.0,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "\n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "\n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "\n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "\n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "\n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI),\n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "\n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI),\n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))\n",
    "\n",
    "        self.partial_train(n_iter)\n",
    "\n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print('\\tcurrent iteration: {}'.format(ctr))\n",
    "            self.user_vecs = self.als_step(self.user_vecs,\n",
    "                                           self.item_vecs,\n",
    "                                           self.ratings,\n",
    "                                           self.user_reg,\n",
    "                                           type='user')\n",
    "            self.item_vecs = self.als_step(self.item_vecs,\n",
    "                                           self.user_vecs,\n",
    "                                           self.ratings,\n",
    "                                           self.item_reg,\n",
    "                                           type='item')\n",
    "            ctr += 1\n",
    "\n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item. \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0],\n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction. \"\"\"\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "\n",
    "    def calculate_learning_curve(self, iter_array, test):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "\n",
    "        The function creates two new class attributes:\n",
    "\n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse = []\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print('Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "\n",
    "class MatrixFactorizationALS:\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 k_factors=40,\n",
    "                 item_reg=0.0,\n",
    "                 user_reg=0.0,\n",
    "                 verbose=False):\n",
    "        self.ratings = ratings\n",
    "        self.users_count = users_count\n",
    "        self.items_count = items_count        \n",
    "        self.k_factors = k_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self._v = verbose\n",
    "        self.curr_iter = 1\n",
    "\n",
    "    def calculate_learning_curve(self, iter_array, test):\n",
    "        iter_array.sort()\n",
    "        self.init_for_train()\n",
    "        training_mse, test_mse = [], []\n",
    "        \n",
    "        for n_iter in iter_array:            \n",
    "            self.print_verbos(f'k={self.k_factors}, '\\\n",
    "                              f'iterations={n_iter}, '\\\n",
    "                              f'item_reg={self.item_reg}, '\\\n",
    "                              f'user_reg={self.user_reg}')\n",
    "            self.train(n_iter)\n",
    "            predictions = self.get_prediction_matrix()\n",
    "            self.evaluate(predictions, training_mse, test_mse, test)  \n",
    "        print('======================')\n",
    "        return training_mse, test_mse\n",
    "    \n",
    "    def als_step_user(self):\n",
    "        YTY = self.item_vecs.T.dot(self.item_vecs)\n",
    "        lambdaI = np.eye(YTY.shape[0]) * self.user_reg\n",
    "\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            self.user_vecs[u, :] = solve((YTY + lambdaI), self.ratings[u, :].dot(self.item_vecs))\n",
    "\n",
    "    def als_step_item(self):\n",
    "        XTX = self.user_vecs.T.dot(self.user_vecs)\n",
    "        lambdaI = np.eye(XTX.shape[0]) * self.item_reg\n",
    "\n",
    "        for i in range(self.item_vecs.shape[0]):\n",
    "            self.item_vecs[i, :] = solve((XTX + lambdaI), self.ratings[:, i].T.dot(self.user_vecs))\n",
    "\n",
    "    def init_for_train(self:\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.normal(scale=1. / self.k_factors,\n",
    "                                          size=(self.users_count, self.k_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1. / self.k_factors,\n",
    "                                          size=(self.items_count, self.k_factors))\n",
    "        print(f'user_vecs: {self.user_vecs.shape}, item_vecs: {self.item_vecs.shape}')\n",
    "\n",
    "\n",
    "    def train(selfת n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. \n",
    "        Can be called multiple times for further training.\n",
    "        \"\"\"\n",
    "        while self.curr_iter <= n_iter:\n",
    "            if self.curr_iter % 10 == 0 and self._v:\n",
    "                print(f'\\tStill running...')\n",
    "                print(f'\\tCurrent iteration: {self.curr_iter}')\n",
    "                \n",
    "            self.als_step_user()\n",
    "            self.als_step_item()\n",
    "            self.curr_iter += 1\n",
    "            \n",
    "    def predict(self, u, i):\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "\n",
    "    def predict_all(self):\n",
    "        predictions = np.zeros((self.user_vecs.shape[0],\n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "        return predictions\n",
    "                       \n",
    "    def evaluate(self, predictions, training_mse, test_mse, test):\n",
    "        training_mse.append(get_mse(predictions, self.ratings))\n",
    "        test_mse.append(get_mse(predictions, test))\n",
    "\n",
    "        self.print_verbos(f'Training MSE = {training_mse[-1]}')\n",
    "        self.print_verbos(f'Test MSE = {test_mse[-1]}')\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [0],\n",
       "             1: [1],\n",
       "             2: [2],\n",
       "             3: [3],\n",
       "             4: [4],\n",
       "             5: [5],\n",
       "             6: [6],\n",
       "             7: [7],\n",
       "             8: [8],\n",
       "             9: [9]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ohad = defaultdict(list)\n",
    "\n",
    "for i in range(10):\n",
    "    ohad[i].append(i)\n",
    "    \n",
    "ohad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplicitMFSGD():\n",
    "    def __init__(self, \n",
    "                 ratings,\n",
    "                 k_factors = 40,\n",
    "                 item_fact_reg = 0.0, \n",
    "                 user_fact_reg = 0.0,\n",
    "                 item_bias_reg = 0.0,\n",
    "                 user_bias_reg = 0.0,\n",
    "                 verbose = False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty entries in a matrix. \n",
    "        The terminology assumes a ratings matrix which is ~ user x item.\n",
    "        \n",
    "        (To avoid overfitting we use regularization)\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        ratings: (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        k_factors: (int)\n",
    "            Number of latent factors to use in matrix factorization model\n",
    "        \n",
    "        item_fact_reg: (float)\n",
    "            Regularization term for item latent factors\n",
    "            \n",
    "        user_fact_reg: (float)\n",
    "            Regularization term for user latent factors\n",
    "            \n",
    "        item_bias_reg: (float)\n",
    "            Regularization term for item biases\n",
    "        \n",
    "        user_bias_reg: (float)\n",
    "            Regularization term for user biases\n",
    "        \n",
    "        verbose: (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.users_count = users_count\n",
    "        self.items_count = items_count\n",
    "        self.k_factors = k_factors\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        \n",
    "        self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "        self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "        self.curr_iter = 1\n",
    "\n",
    "        \n",
    "    def calculate_learning_curve(self, iter_array, test, learning_rate):\n",
    "        iter_array.sort()\n",
    "        self.init_for_train(learning_rate)\n",
    "        training_mse, test_mse = [], []\n",
    "        \n",
    "        for n_iter in iter_array:            \n",
    "            self.print_verbose(f'k={self.k_factors}, alpha={learning_rate}, '\\\n",
    "                              f'iterations={n_iter}, item_fact_reg={self.item_fact_reg}, '\\\n",
    "                              f'user_fact_reg={self.user_fact_reg}, item_bias_reg={self.item_bias_reg}, '\\\n",
    "                              f'user_bias_reg={self.user_bias_reg}')\n",
    "            self.train(n_iter)\n",
    "            predictions = self.get_prediction_matrix()\n",
    "            self.evaluate(predictions, training_mse, test_mse, test)\n",
    "            \n",
    "        print('======================')\n",
    "        \n",
    "        return training_mse, test_mse\n",
    "    \n",
    "    \n",
    "    def init_for_train(self, learning_rate=0.1):        \n",
    "        # initialize latent vectors\n",
    "        # Approximate rating matrix by product of lower rank matrix\n",
    "        self.user_vecs = np.random.normal(scale=1./self.k_factors, size=(self.users_count, self.k_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.k_factors, size=(self.items_count, self.k_factors))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.user_bias = np.zeros(self.users_count)\n",
    "        self.item_bias = np.zeros(self.items_count)\n",
    "        self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "\n",
    "    def train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. \n",
    "        Can be called multiple times for further training.\n",
    "        \"\"\"\n",
    "        while self.curr_iter <= n_iter:\n",
    "            if self.curr_iter % 10 == 0 and n_iter > 10 and self._v:\n",
    "                print(f'\\tStill running...')\n",
    "                print(f'\\tCurrent iteration: {self.curr_iter}')\n",
    "                \n",
    "            self.training_indices = np.arange(self.n_samples)\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.perform_sgd()\n",
    "            self.curr_iter += 1\n",
    "            \n",
    "    def predict(self, user, item):\n",
    "        \"\"\"\n",
    "        Single user and item prediction\n",
    "        \"\"\"\n",
    "        biases = self.global_bias + self.user_bias[user] + self.item_bias[item]\n",
    "        prediction_value = biases + self.user_vecs[user, :].dot(self.item_vecs[item, :].T)\n",
    "        \n",
    "        return prediction_value\n",
    "    \n",
    "    def perform_sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "            user = self.sample_row[idx]\n",
    "            item = self.sample_col[idx]\n",
    "            prediction = self.predict(user, item)\n",
    "            actual_rating = self.ratings[user, item] # get actual rating from the dataset's ratings array \n",
    "            error = actual_rating - prediction\n",
    "            \n",
    "            # Update biases\n",
    "            self.user_bias[user] += self.learning_rate * (error - self.user_bias_reg * self.user_bias[user])\n",
    "            self.item_bias[item] += self.learning_rate * (error - self.item_bias_reg * self.item_bias[item])\n",
    "            \n",
    "            # Update latent factors\n",
    "            self.user_vecs[user, :] += self.learning_rate * (error * self.item_vecs[item, :] - self.user_fact_reg * self.user_vecs[user,:])\n",
    "            self.item_vecs[item, :] += self.learning_rate * (error * self.user_vecs[user, :] - self.item_fact_reg * self.item_vecs[item,:])\n",
    "    \n",
    "    def get_prediction_matrix(self):\n",
    "        \"\"\"\n",
    "        Predict ratings for every user and item\n",
    "        \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        \n",
    "        for user in range(self.user_vecs.shape[0]):\n",
    "            for item in range(self.item_vecs.shape[0]):\n",
    "                predictions[user, item] = self.predict(user, item)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, predictions, training_mse, test_mse, test):\n",
    "        training_mse.append(get_mse(predictions, self.ratings))\n",
    "        test_mse.append(get_mse(predictions, test))\n",
    "\n",
    "        self.print_verbose(f'Training MSE = {training_mse[-1]}')\n",
    "        self.print_verbose(f'Test MSE = {test_mse[-1]}')\n",
    "\n",
    "    def print_verbose(self, msg):\n",
    "        if self._v:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "user_vecs: (943, 40), item_vecs: (1682, 40)\n",
      "Train mse: 5.508768969828915\n",
      "Test mse: 9.803011129993122\n",
      "Iteration: 2\n",
      "Train mse: 4.211806356215287\n",
      "Test mse: 8.651950992137149\n",
      "Iteration: 5\n",
      "Train mse: 3.9684131825311786\n",
      "Test mse: 8.465987678112086\n",
      "Iteration: 10\n",
      "Train mse: 3.9338102082318858\n",
      "Test mse: 8.448744189802962\n",
      "Iteration: 25\n",
      "\tcurrent iteration: 10\n",
      "Train mse: 3.925227446759353\n",
      "Test mse: 8.451516825902674\n",
      "Iteration: 50\n",
      "\tcurrent iteration: 10\n",
      "\tcurrent iteration: 20\n",
      "Train mse: 3.9242229016201344\n",
      "Test mse: 8.46562199755438\n",
      "Iteration: 100\n",
      "\tcurrent iteration: 10\n",
      "\tcurrent iteration: 20\n",
      "\tcurrent iteration: 30\n",
      "\tcurrent iteration: 40\n",
      "\tcurrent iteration: 50\n",
      "Train mse: 3.923497245580798\n",
      "Test mse: 8.466999943345845\n"
     ]
    }
   ],
   "source": [
    "MF_ALS = MatrixFactorizationALS(train, n_factors=40, \\\n",
    "                    user_reg=0.0, item_reg=0.0, verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 100]\n",
    "MF_ALS.calculate_learning_curve(iter_array, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "def plot_learning_curve(iter_array, model):\n",
    "    plt.plot(iter_array, model.train_mse, \\\n",
    "             label='Training', linewidth=5)\n",
    "    plt.plot(iter_array, model.test_mse, \\\n",
    "             label='Test', linewidth=5)\n",
    "\n",
    "\n",
    "    plt.xticks(fontsize=16);\n",
    "    plt.yticks(fontsize=16);\n",
    "    plt.xlabel('iterations', fontsize=30);\n",
    "    plt.ylabel('MSE', fontsize=30);\n",
    "    plt.legend(loc='best', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(iter_array, MF_ALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
